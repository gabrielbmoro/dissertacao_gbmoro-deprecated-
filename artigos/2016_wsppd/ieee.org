# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Automatic Memory-Bound Phase Detection using Time-oriented Hardware Counters Metrics
#+AUTHOR: Gabriel Bronzatti Moro, Lucas Mello Schnorr

#+STARTUP: overview indent
#+LANGUAGE: pt-br
#+OPTIONS: H:3 creator:nil timestamp:nil skip:nil toc:nil num:t ^:nil ~:~
#+OPTIONS: author:nil title:nil date:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)  Gabriel(G) Lucas(L)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_CLASS: IEEEtran
#+LATEX_CLASS_OPTIONS: [conference,letter,10pt,final]
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{lipsum}

# You need Org 8.3.5 and Emacs 24 to make this work.
# If you do, just type make (thanks Luka Stanisic for this).

* Gráficos                                                         :noexport:
** Plot da FT

#+begin_src R :results output graphics :file "img/ftBNas_Analise.pdf" :exports both :session *RFib*  :width 8 :height 4

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");
#+end_src

#+RESULTS:
[[file:img/ftBNas_Analise.pdf]]


#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:       Time Metric Socket  N     mean          se
: 1 9.832468     M7      1 16 31.00176 0.002447148
:        Time Metric Socket  N     mean          se
: 1 0.3410059     M7      1 16 6.786985 0.005029964

** Plot da LU
#+begin_src R :results output graphics :file "img/luBNas_Analise.pdf" :exports both :session *RFib* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/luBNas_Analise.pdf]]


#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
      Time Metric Socket  N     mean         se
1 33.42106     M7      2 16 27.99985 0.04944031
       Time Metric Socket  N     mean         se
1 0.1006167     M7      1 16 10.88676 0.02663008
#+end_example


** Plot da CG

#+begin_src R :results output graphics :file "img/cgBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/cgBNas_Analise.pdf]]


#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:       Time Metric Socket  N    mean         se
: 1 23.69983     M7      2 16 38.6508 0.02485503
:         Time Metric Socket  N     mean        se
: 1 0.05055852     M7      1 16 10.21882 0.0773729

** Plot do SP
#+begin_src R :results output graphics :file "img/spBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/spB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/spBNas_Analise.pdf]]

** Plot do UA

#+begin_src R :results output graphics :file "img/uaBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/uaB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/uaBNas_Analise.pdf]]

* Conversas e definições sobre o artigo                            :noexport:
** Proposta de Estrutura para o Artigo                              :Gabriel:
- Professor, acho interessante a seguinte estrutura para escrevermos
  nosso artigo:

#+BEGIN_EXAMPLE
1. Introduction 


2. Related Works PRAZO - ATÉ Sexta-feira 05/08
     - Utilizar os trabalhos: Laurenzano e Freeh 
     - Procurar mais alguns a apartir de um mapeamento sistemático da literatura

3. Methodology
     - Penso aqui em apresentar as características do DoE realizado para executar o experimento (PRAZO - ATÉ Segunda-feira 08/08)

4. Preliminary Results PRAZO - ATÉ Terça-feira 09/08
      - Penso aqui em usar o benchmark Rodinia executando duas aplicações, uma chamada BFS (representando uma aplicação memory-bound) e a Back Propagation (representando uma aplicação cpu-bound)

5. Conclusion PRAZO - ATÉ Terça-feira 09/08
      p1: comentar resultados

    5.1 Future Work
#+END_EXAMPLE

** Por que BFS e Back Propagation como benchmarks?                   :Lucas:

Estávamos usando a orion3 para realizar os experimentos relacionados a
energia, pois a turing não tem suporte RAPL para isso. Mas como tu por
enquanto não está medindo isso, apenas os contadores, acho que tudo
bem. É importante ter consciência que os contadores disponíveis em uma
máquina com suporte de medição de energia podem potencialmente ser
diferentes dos contadores disponíveis na turing. Estou curioso para
ver as primeiras medições. Todas as medidas devem ser registradas em
arquivos CSV no próprio repositório (quando o tamanho é adequado para
git - arquivos de mais de 10 mega começam a ser questionáveis). 

Teus deadlines me parecem adequados, mas o ideal é que o processo
fosse iterativo. O ideal seria terminar tudo até essa sexta 5/ago para
permitir bons refinamentos. Avisa-me quando estiver com algo passível
de leitura. 

*** Resposta:                                                     :Gabriel:
Olá professor, perfeitamente, o senhor sabe que estávamos pensando em
quais contadores usar, nisso avaliando a fundo o artigo do *Laurenzano
et al.*, foi possível encontrar que no experimento ele utilizou
contadores para estimar a taxa de hit dos diferentes níveis de cache,
outro contador para contabilizar a quantidade de operações de
ponto-flutuante realizadas e a quantidade de operações FP realizadas
sobre inteiro. A partir disso, eu investiguei os contadores
disponibilizados pelo PAPI, e dentre eles, para identificar o que
queremos, podemos usar os seguintes: *PAPI_L1_DCA* (acessos à L1),
*PAPI_L2_DCA* (acessos à L2), *PAPI_L3_DCA* (acessos à L3), *PAPI_L1_DCH*
(taxa de hits da L1), *PAPI_L2_DCH* (taxa de hits da L2) e *PAPI_L3_DCA*
(número de misses na L3). Vale lembrar, que ainda tenho que verificar
a disponibilidade desses contadores na =turing=, a mesma está bloqueada:

#+begin_src sh :results output :exports both
gbmoro@portal:~$ ssh -X gabrielbmoro@turing
gabrielbmoro@turing's password: 
Welcome to Ubuntu 12.04.5 LTS (GNU/Linux 3.13.0-48-generic x86_64)

 * Documentation:  https://help.ubuntu.com/

  System information as of Thu Aug  4 00:19:56 BRT 2016

  System load:    0.05              Processes:             602
  Usage of /home: 31.0% of 4.51TB   Users logged in:       1
  Memory usage:   2%                IP address for eth0:   143.54.12.105
  Swap usage:     0%                IP address for virbr0: 192.168.122.1

  Graph this data and manage this system at:
    https://landscape.canonical.com/

166 packages can be updated.
112 updates are security updates.

New release '14.04.1 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Your Hardware Enablement Stack (HWE) is supported until April 2017.

Please DO NOT install packages or create users without talking to the admins.

Last login: Wed Aug  3 23:08:54 2016 from portal.inf.ufrgs.br
locked by user 'vemabaunza' at Wed Aug  3 18:43:52 BRT 2016
-m Victor Martinez - sera liberada 4/08/2016 de manha
Connection to turing closed.

#+end_src

- Quanto aos traces gerados, esses estão na turing, e não os commitei
  para o git por causa do tamanho. Vou fazer uma execução na =turing=
  usando o minibench o que o senhor acha?
  Esse minibench tem mini-aplicações (ideia sugerida pelo Matthias),
  as quais são rápidas de executar, permitindo que o experimento seja
  executado mais rapidamente e que eu possa já na sexta-feira ter um
  volume de trabalho significativo (primeira versão do artigo). Nunca
  trabalhei com o minibench, mas acho uma boa ideia. 

Mensionei o BFS, porque aplicações que utilizam grafos, tendem a ser
memory-bound, pois o índice de cache miss nessas aplicações é muito
alto, visto que o grafo não é armazenado de maneira contínua na
memória é via referência, o processo de busca envolve vários
acessos à memória, podendo gerar vários misses. Depois pensei na Back
Propagation, porque comparado ao BFS, ela é uma aplicação mais
CPU-bound, o que seria interessante analisar nas diferentes fases o
comportamento dessas duas aplicações paralelas. Mas depois, o Matthias
me falou do MiniBench, o que achei interessante e que pode nos ajudar,
o que o senhor acha?

* IEEETran configuration for org export + ignore tag (Start Here)  :noexport:

#+begin_src emacs-lisp :results output :session :exports both
(add-to-list 'load-path ".")
(require 'ox-extra)
(ox-extras-activate '(ignore-headlines))
(add-to-list 'org-latex-classes
             '("IEEEtran"
               "\\documentclass{IEEEtran}"
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src

#+RESULTS:

* *The Paper*                                                       :ignore:
** Latex configurations                                             :ignore:
** Frontpage                                                        :ignore:
#+BEGIN_LaTeX
\title{Automatic Memory-Bound Phase Detection \\ using Time-oriented Hardware Counters Metrics}

\author{
\IEEEauthorblockN{Gabriel Bronzatti Moro, Lucas Mello Schnorr}
\IEEEauthorblockA{Institute of Informatics, Federal University of Rio Grande do Sul \\
Caixa Postal 15064 –- CEP 91501-970 Porto Alegre -- RS -- Brazil\\}
}
#+END_LaTeX

#+LaTeX: \maketitle

** Abstract                                                         :ignore:

#+LaTeX: \begin{abstract}
Besides reducing the execution time of parallel applications, the power
consumption is an increasingly addressed problem in High-Performance
Computing. A parallel program may be composed of different
parallel regions, which can have particular characteristics, for instance,
CPU or memory bound. This paper presents an
approach that allows the automated detection of memory-bound parallel
regions. Our approach differs from others found in the literature
because it detects automatically parallel regions that depend more
of the memory, all samples collected from the application did not require
any code instrumentation, advantage of the present work, the
less intrusive possible. The applications used in the experiment
were the Discrete 3D fast Fourier Transform (FT), Lower-Upper
Gauss-Seidel solver and Conjugate Gradient, both of the NAS benchmark
parallel. In the experiment was evaluated the miss rate for the L2
cache. Through of the experiment was possible to identify the memory-bound
regions by timestamps of the applications. The results show that is
possible to identify the memory-bound regions and too the behavior of
applications as a whole. From the knowledge of these regions it is
possible to configure a suitable processor frequency for each parallel
region of the application, reducing the energy used and improving the
performance of the application as a whole. 
#+LaTeX: \end{abstract}

** Introduction

#+LaTeX: %- Large HPC applications are usually composed by many parallel regions
  #+LaTeX: %- Give some examples

Large HPC applications are composed of parallel regions, these regions
may be regarded program fragments that are executed by different
threads. For example, in an application that calculates heat exchange
in a metal plate, could be considered a problem which has two sets of
parallel regions, the first set calculate the initial state of the
plate and another part would be responsible for calculating the heat
exchange in different points of the plate. In the first set there are
various parallel regions, whether divided in "n" timestamps, it is
possible to see various behaviors, some more memory-bound, others more
CPU-bound. 

#+LaTeX: %- Each code region has its own memory/cpu/io resource requirements
  #+LaTeX: %- Some might be more memory-bound, others cpu-bound, for example

Each parallel region has its own characteristic, some may be
considered memory-bound, where there is a high rate of the
cache miss, while others may be considered more CPU-bound, which
expects more by CPU resource and more IO-bound when the thread is
limited by waiting for input or output operations. In the previous
example of the heat plate, the second  set of parallel regions can be
considered more memory-bound than the first set, more within of each
set may exists regions with behaviors various.  

#+LaTeX: %- Automatically detecting such regions could potentially lead to
  #+LaTex: % per-parallel region improvements such as energy and performance
  #+LaTeX: % improvements by adopting an appropriate processor frequency to
  #+LaTeX: % execute

From an automatic detection of parallel regions of an application it
is possible to adjust the processor to frequency appropriate to the
region, according to its features (memory or CPU bound), which may allow
a reduction in energy consumption and an increase application
performance as a whole.

#+LaTeX: %- The idea of this work is to measure hardware counters along time in
#+LaTeX: %  order to correlate their values against the different code region
#+LaTeX: %  - With this information, we intend to detect memory-bound code
#+LaTeX: %    regions that could be potential candidates for energy reduction
#+LaTeX: %    strategies (mainly DVFS)
#+LaTeX: %  - Once the memory-bound code regions have been detected, we intend
#+LaTeX: %    to apply Design of Experiments techniques to find the best
#+LaTeX: %    processor frequency configuration for each region, pretty similar
#+LaTeX: %    to what has been done already lfgmillani2016reppar, but
#+LaTeX: %    automatically.

The main objective of this study is to measure hardware counters
specific for each parallel region code to define regions
having more memory-bound behavior, which could be
candidates for strategies to reduce energy consumption (using
Dynamic Voltage Frequency Scaling).

# We intend to apply the technique of Design of
# Experiments\cite{jain1990art} to find the best frequency setting for
# each region automatically and with a lower level of intrusion compared
# to instrumentation of the source code. 

The preliminary results indicate that the technique used in this work
allows automated identification of the memory-bound regions in a
parallel application with a low level of intrusion, different
approaches investigated \cite{freeh2005exploring,millani2006fr}. In
addition to identifying regions, it is also possible to identify the
behavior of the application as a whole based on different hardware
counters.  

#+LaTeX: %- Paper structure

This paper has the following
organization. Section \ref{sec:relatedwork} presents related work
regarding automatic phase detection for HPC applications. It also
motivates our work. Section \ref{sec:methodology} details our proposal
and its corresponding methodology to fullfill our goal, which is the
automatic phase detection using time-oriented hardware
counters. Section \ref{sec:results} the plataform we have been using
to conduct experiments and the preliminary results we have obtained so
far. Section \ref{sec:conclusion} concludes the paper listing the main
contributions and future work.   

*** Previous structure (in portuguese)                           :noexport:

- contextualizar o problema, relacionando o trabalho já feito pelo
  Luís Felipe, o porque pensar numa detecção automatizada da troca de
  fase entre as threads, o que o trabalho poderá somar ao projeto
  existente.

- apresentar o objetivo do trabalho, o qual será apresentado como um
  "estudo de viabilidade" do trabalho, mostrando que é possível
  realizá-lo técnicamente e que esse é um dos passos fundamentais para
  colocá-lo em prática

- análisar os resultados preliminares

- apresentar a organização do artigo

_Revisão Lucas_

- Cuidar a escrita em português, veja o acento nestas palavras
  - tecnicamente
  - analisar
- 

** Related Work
\label{sec:relatedwork}

#+LaTeX: %- There is no definitive solution to detect if a code region is more
#+LaTeX:  %memory or CPU bound.
#+LaTeX:  %- Usually hard. counters are globally aggregated
#+LaTeX:  %- Automatic techniques usually rely on specific hardware counters

There is no definitive solution to detect if a code region is more
memory or CPU bound. The main focus of this work is to characterize
the behavior of code regions of a parallel application, classifying
them into memory and/or CPU bound. For thereafter to be able to find
an appropriate frequency for each region, using DVFS (Dynamic Voltage
Frequency Scaling) technique.

Some works focus more on phase detection to sequential applications
\cite{spiliopoulos2012power}\cite{laurenzano2011reducing}. Spiliopoulos
et al.\cite{spiliopoulos2012power} present in his work a tool that
analyzes the behavior of a sequential application by detailed analysis
of its phases of execution, based on cache misses of the different
levels of cache, the tool identifies the best processor frequency to
be used in each phase to best performance and reduce energy
consumption. In addition to this approach, Laurenzano et
al.\cite{laurenzano2011reducing} present an approach finer granularity
for identifying the most appropriate processor frequency for each loop
of application. From the executions, it is defined a model of multiple
dimensions that allows find given loop frequency that best defines the
behavior of energy and expected performance. 

For parallel applications, there is advances in the detection of
stages for MPI applications \cite{freeh2005exploring}, already to
OpenMP applications, there is one approach that allows the
instrumentation via code to indicate the parallel regions
\cite{millani2006fr}. Freeh et al.\cite{freeh2005exploring} present an 
approach that to provide the most suitable frequency for each phase of
an MPI application, the application of this approach is divided
according to the number of cluster processors used. Among the
available frequencies, the approach looks at what is the best
frequency for a given node operate during the execution of the
application.

An approach that focuses on shared memory applications in OpenMP is
Millani and Schnorr \cite{millani2006fr}. In this work are analyzed
parallel regions of a program, according to the study it is possible
to reach a considerable gain in energy reduction and performance
increase through the use of a suitable frequency for each parallel
region of the program. Also, in this approach the parallel regions are
instrumented, already in our work the parallel regions will be known
during program execution, the level of intrusion of our approach is
lower and it is possible to identify the behavior of the memory-bound
regions and from these reduce the processor frequency, lowering power
consumption and improving performance. 

** Methodology
\label{sec:methodology}

The methodology used in the work first defines the compilation a
source code into binary after that to run this program is used to a
likwid-perfctr tool that allows you to collect events each processing
core. These events are processed by a script we created to generate a
detailed trace of the application for make the data analysis. In the
Figure \ref{figMetodologia} it is possible to see an overview of the
methodology.

#+LaTeX: \begin{figure}[!htb] \label{figMetodologia}
#+LaTeX:   \caption{Overview of the methodology.}
#+LaTeX:     \includegraphics[width=8cm,height=9cm]{img/metodologiaWorkWsppd2016.pdf}
#+LaTeX: \end{figure}



In the experiment were used OpenMP applications of the NAS Parallel
Benchmarks. These applications were chosen two, the 3D Discrete Fast
Fourier Transform (FT), Lower-Upper Gauss-Seidel Solver (LU) and
Conjugate Gradient (CG), because in them it is possible to see two
very different behaviors in misses rate for the L2 Cache when compared
to other applications of the benchmark. 

The applications were executed with 32 threads, both applications used
the bigger input size (class B) of the benchmark. The execution
platform used was a Workstation with 2 processors Intel (R) Xeon (R)
E5-2650 CPU 2.00 GHz, each with 8 physical cores and Hyper-Threading
technology. 

To understand the behavior of the memory-bounds parallel regions was
used to likwid tool that allowed collecting in each timestamp basic
measures over the miss rate to the L2 Cache. The interval between
timestamps was defined according to the total execution time of each
application. For example, in the FT application, the interval was
between timestamps was 30ms (milliseconds) generating about 172
samples (for each of the 32 threads). Already for the LU application
was defined a wider range of 100ms, which generated about 363
samples. The wider range defined for the CG application was 50ms,
which generated about 384 samples. 

** Preliminary Results
\label{sec:results}

The graphs have two lines, the first describes the miss
rate behavior in the L2 cache to the first processor (socket with
8-physical colors) and the second line to the other processor. Each
point on the graph presents a coordinated, where was a sample
collected on their timestamp. 

#+LaTeX: \begin{figure}[!htb] \label{figFT}
#+LaTeX:   \caption{Execution of the Discrete 3D fast Fourier Transform.}
#+LaTeX:     \includegraphics[width=9cm]{img/ftBNas_Analise.pdf}
#+LaTeX: \end{figure}

The execution of the FT application (in the Figure \ref{figFT}) show a
similar behavior of the first processor and also the second. In the
course of execution, it is possible to see a homogeneous behavior of
the application, a peak occurs in a sample collected of the first CPU
reaching about 31% to rate misses of L2 cache in 9.83 seconds of
execution. This region can be considered more memory-bound than the
others, but the application as a whole presents a more CPU-bound
behavior. The lowest misses cache rate found was 6.78% at the very
beginning of the run in 0,34 seconds.

#+LaTeX: \begin{figure}[!htb] \label{figLU}
#+LaTeX:   \caption{Execution of the Lower-Upper Gauss-Seidel solver.}
#+LaTeX:     \includegraphics[width=7.8cm,height=6.8cm]{img/luBNas_Analise.pdf}
#+LaTeX: \end{figure}

Unlike the previous application, the LU application (Figure
\ref{figLU}) has an totally erratic behavior on cache misses rate
level L2 cache. The most memory-bound region (more misses rate) was
found in the timestamp of 33.42 seconds run about 27.99% of misses the
second CPU. Already the lowest rate was found in first seconds of the
application executing on the first CPU, about 10% of misses. 

#+LaTeX: \begin{figure}[!htb] \label{figLU}
#+LaTeX:   \caption{Execution of Conjugate Gradient.}
#+LaTeX:     \includegraphics[width=7.8cm,height=6.8cm]{img/cgBNas_Analise.pdf}
#+LaTeX: \end{figure}


It is possible to see the execution's graphic of the CG application,
different of  FT and LU applications, the behavior of the running line
starts with increasing the miss rate, then the behavior is
static so that the rate remains linearly. The higher rate of
miss approached 40% for this application to the CPU 2, already the
smallest miss rate was found for the CPU 1, about 10%. This
application  has a more behavior memory-bound than the other. If we
find an ideal frequency for one of the parallel regions, most parts of
the application could benefit from the same frequency since the CG
application has its parallel regions similar rate of misses. 

** Conclusion
\label{sec:conclusion}

The results show that is possible to identify regions with more
memory-bound in parallel applications. The three parallel applications
used were chosen to visualize the behavior of an application that has
cache misses that occur in a focused and homogeneously (FT
application), an application a fully variable misses rate during
runtime (LU) and an application with a considerable cache miss rate 
(CG).

Not all tools offer adequate support to collect counters in hardware
small time intervals (msec range), the tool used (likwid) provided the
values of the respective counters hardware of time slices requested
timestamp defined in the experiments, allowing examine other
characteristics to define memory-bounds areas of a parallel
application. 

The next step of the work consists of the following steps: explore
other measures to define with greater accuracy the memory-bound
regions, align the technique of Design of Experiments in our
methodology and use the DVFS application for efficiency energy and
higher performance for applications specifically identified in the
parallel memory-bound regions. 


#+LATEX:%\section*{Acknowledgements}

#+LaTeX: %Who paid for this?

** References                                                        :ignore:

# See next section to understand how refs.bib file is created.

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{refs}

* Bib file is here                                                 :noexport:

Tangle this file with C-c C-v t

#+begin_src bib :tangle refs.bib

@inproceedings{freeh2005exploring,
  title={Exploring the energy-time tradeoff in mpi programs on a power-scalable cluster},
  author={Freeh, Vincent W and Pan, Feng and Kappiah, Nandini and Lowenthal, David K and Springer, Robert},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium},
  pages={4a--4a},
  year={2005},
  organization={IEEE}
}

@inproceedings{laurenzano2011reducing,
  title={Reducing energy usage with memory and computation-aware dynamic frequency scaling},
  author={Laurenzano, Michael A and Meswani, Mitesh and Carrington, Laura and Snavely, Allan and Tikir, Mustafa M and Poole, Stephen},
  booktitle={European Conference on Parallel Processing},
  pages={79--90},
  year={2011},
  organization={Springer}
}

@inproceedings{spiliopoulos2012power,
  title={Power-Sleuth: A Tool for Investigating Your Program's Power Behavior},
  author={Spiliopoulos, Vasileios and Sembrant, Andreas and Kaxiras, Stefanos},
  booktitle={2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},
  pages={241--250},
  year={2012},
  organization={IEEE}
}

@incollection{schnorr2013visualizing,
  title={Visualizing More Performance Data Than What Fits on Your Screen},
  author={Schnorr, Lucas M and Legrand, Arnaud},
  booktitle={Tools for High Performance Computing 2012},
  pages={149--162},
  year={2013},
  publisher={Springer}
}

@article{millani2006fr,
author = {Millani, Luis Felipe and Schnorr, Lucas Mello},
title={Computation-Aware Dynamic Frequency Scaling: Parsimonious Evaluation of the Time-Energy Trade-off Using Design of Experiments},
year={2016},
publisher={22nd International European Conference on Parallel and Distributed Computing}
}



#+end_src
