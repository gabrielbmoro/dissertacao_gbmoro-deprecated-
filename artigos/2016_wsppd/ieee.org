# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Measuring Hardware Counters  for HPC Application Phase Detection
#+AUTHOR: Gabriel Bronzatti Moro, Lucas Mello Schnorr

#+STARTUP: overview indent
#+LANGUAGE: pt-br
#+OPTIONS: H:3 creator:nil timestamp:nil skip:nil toc:nil num:t ^:nil ~:~
#+OPTIONS: author:nil title:nil date:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)  Gabriel(G) Lucas(L)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_CLASS: IEEEtran
#+LATEX_CLASS_OPTIONS: [conference,letter,10pt,final]
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{lipsum}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \newcommand{\review}[1]{\textcolor[rgb]{1,0,0}{[Lucas: #1]}}

# You need Org 8.3.5 and Emacs 24 to make this work.
# If you do, just type make (thanks Luka Stanisic for this).

* Gráficos                                                         :noexport:
** Plot da FT
*** L2

#+begin_src R :results output graphics :file "img/ftBNas_Analise.pdf" :exports both :session *RFib* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/ftBNas_Analise.pdf]]

#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:       Time Metric Socket  N     mean          se
: 1 9.832468     M7      1 16 31.00176 0.002447148
:        Time Metric Socket  N     mean          se
: 1 0.3410059     M7      1 16 6.786985 0.005029964

*** L3
#+begin_src R :results output graphics :file "img/ftBNas_Analise_l3.pdf" :exports both :session *RFib* 

library(dplyr);

df <- read.csv("../../dados/exp2_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L3 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/ftBNas_Analise_l3.pdf]]

#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp2_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:        Time Metric Socket  N     mean        se
: 1 0.2776482     M7      1 16 37.61564 0.2987426
:       Time Metric Socket  N       mean           se
: 1 8.711887     M7      1 16 0.02094844 5.839419e-05

** Plot da LU
*** L2

#+begin_src R :results output graphics :file "img/luBNas_Analise.pdf" :exports both :session *RFib* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:       Time Metric Socket  N     mean         se
: 1 33.42106     M7      2 16 27.99985 0.04944031
:        Time Metric Socket  N     mean         se
: 1 0.1006167     M7      1 16 10.88676 0.02663008

*** L3

#+begin_src R :results output graphics :file "img/luBNas_Analise_l3.pdf" :exports both :session *RFib* 

library(dplyr);

df <- read.csv("../../dados/exp2_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L3 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/luBNas_Analise_l3.pdf]]


#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp2_NASandLikwid/luB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:        Time Metric Socket  N     mean        se
: 1 0.1005844     M7      1 16 13.77685 0.1511483
:       Time Metric Socket  N       mean           se
: 1 36.26222     M7      2 16 0.07087374 0.0005140726

** Plot da CG
*** L2

#+begin_src R :results output graphics :file "img/cgBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/cgBNas_Analise.pdf]]

#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp1_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:       Time Metric Socket  N    mean         se
: 1 23.69983     M7      2 16 38.6508 0.02485503
:         Time Metric Socket  N     mean        se
: 1 0.05055852     M7      1 16 10.21882 0.0773729


*** L3
#+begin_src R :results output graphics :file "img/cgBNas_Analise_l3.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp2_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L3 Cache Misses (%)");

#+end_src


#+RESULTS:
[[file:img/cgBNas_Analise_l3.pdf]]

#+begin_src R :results output :session *R* :exports both
library(dplyr);
df <- read.csv("../../dados/exp2_NASandLikwid/cgB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();

k$Socket <- ifelse(k$Core %% 2 == 0,1,2);

g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();

#identificando o maior valor
maxG <- max(g$mean);
g1_g <- filter(g,mean==maxG);
g1_g

#identificando o menor valor
minG <- min(g$mean);
g2_g <- filter(g,mean==minG);
g2_g

#+end_src

#+RESULTS:
:         Time Metric Socket  N     mean        se
: 1 0.05055831     M7      2 16 23.65833 0.2532902
:       Time Metric Socket  N        mean           se
: 1 21.36921     M7      2 16 0.004947738 1.722305e-05

** Plot do SP
#+begin_src R :results output graphics :file "img/spBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/spB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/spBNas_Analise.pdf]]

#+begin_src R :results output graphics :file "img/spBNas_Analise_l3.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp2_NASandLikwid/spB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L3 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/spBNas_Analise_l3.pdf]]

** Plot do UA

#+begin_src R :results output graphics :file "img/uaBNas_Analise.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp1_NASandLikwid/uaB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L2 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/uaBNas_Analise.pdf]]

#+begin_src R :results output graphics :file "img/uaBNas_Analise_l3.pdf" :exports both :session *RF* 

library(dplyr);

df <- read.csv("../../dados/exp2_NASandLikwid/uaB.csv", sep=" ", strip.white=T);
k <-    filter(df, df$Metric=='M7') %>% as.data.frame();
k <- 	arrange(k,as.integer(k$Core));
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
middle <- mean(k$Value);
k$Socket <- ifelse(k$Core %% 2 == 0,1,2);
g <- k %>% group_by(Time,Metric,Socket) %>% summarize (N=n(), mean=mean(Value)*100, se=3*sd(Value)/sqrt(N)) %>% as.data.frame();
library(ggplot2);
ggplot(g[g$Metric == "M7",], aes(x=Time, y=mean,color=as.factor(Socket))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,100) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="CPU Socket") +
      labs(x = "Runtime (seconds)", y= "Average L3 Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/uaBNas_Analise_l3.pdf]]

* Conversas e definições sobre o artigo                            :noexport:
** Proposta de Estrutura para o Artigo                              :Gabriel:
- Professor, acho interessante a seguinte estrutura para escrevermos
  nosso artigo:

#+BEGIN_EXAMPLE
1. Introduction 


2. Related Works PRAZO - ATÉ Sexta-feira 05/08
     - Utilizar os trabalhos: Laurenzano e Freeh 
     - Procurar mais alguns a apartir de um mapeamento sistemático da literatura

3. Methodology
     - Penso aqui em apresentar as características do DoE realizado para executar o experimento (PRAZO - ATÉ Segunda-feira 08/08)

4. Preliminary Results PRAZO - ATÉ Terça-feira 09/08
      - Penso aqui em usar o benchmark Rodinia executando duas aplicações, uma chamada BFS (representando uma aplicação memory-bound) e a Back Propagation (representando uma aplicação cpu-bound)

5. Conclusion PRAZO - ATÉ Terça-feira 09/08
      p1: comentar resultados

    5.1 Future Work
#+END_EXAMPLE

** Por que BFS e Back Propagation como benchmarks?                   :Lucas:

Estávamos usando a orion3 para realizar os experimentos relacionados a
energia, pois a turing não tem suporte RAPL para isso. Mas como tu por
enquanto não está medindo isso, apenas os contadores, acho que tudo
bem. É importante ter consciência que os contadores disponíveis em uma
máquina com suporte de medição de energia podem potencialmente ser
diferentes dos contadores disponíveis na turing. Estou curioso para
ver as primeiras medições. Todas as medidas devem ser registradas em
arquivos CSV no próprio repositório (quando o tamanho é adequado para
git - arquivos de mais de 10 mega começam a ser questionáveis). 

Teus deadlines me parecem adequados, mas o ideal é que o processo
fosse iterativo. O ideal seria terminar tudo até essa sexta 5/ago para
permitir bons refinamentos. Avisa-me quando estiver com algo passível
de leitura. 

*** Resposta:                                                     :Gabriel:
Olá professor, perfeitamente, o senhor sabe que estávamos pensando em
quais contadores usar, nisso avaliando a fundo o artigo do *Laurenzano
et al.*, foi possível encontrar que no experimento ele utilizou
contadores para estimar a taxa de hit dos diferentes níveis de cache,
outro contador para contabilizar a quantidade de operações de
ponto-flutuante realizadas e a quantidade de operações FP realizadas
sobre inteiro. A partir disso, eu investiguei os contadores
disponibilizados pelo PAPI, e dentre eles, para identificar o que
queremos, podemos usar os seguintes: *PAPI_L1_DCA* (acessos à L1),
*PAPI_L2_DCA* (acessos à L2), *PAPI_L3_DCA* (acessos à L3), *PAPI_L1_DCH*
(taxa de hits da L1), *PAPI_L2_DCH* (taxa de hits da L2) e *PAPI_L3_DCA*
(número de misses na L3). Vale lembrar, que ainda tenho que verificar
a disponibilidade desses contadores na =turing=, a mesma está bloqueada:

#+begin_src sh :results output :exports both
gbmoro@portal:~$ ssh -X gabrielbmoro@turing
gabrielbmoro@turing's password: 
Welcome to Ubuntu 12.04.5 LTS (GNU/Linux 3.13.0-48-generic x86_64)

 * Documentation:  https://help.ubuntu.com/

  System information as of Thu Aug  4 00:19:56 BRT 2016

  System load:    0.05              Processes:             602
  Usage of /home: 31.0% of 4.51TB   Users logged in:       1
  Memory usage:   2%                IP address for eth0:   143.54.12.105
  Swap usage:     0%                IP address for virbr0: 192.168.122.1

  Graph this data and manage this system at:
    https://landscape.canonical.com/

166 packages can be updated.
112 updates are security updates.

New release '14.04.1 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Your Hardware Enablement Stack (HWE) is supported until April 2017.

Please DO NOT install packages or create users without talking to the admins.

Last login: Wed Aug  3 23:08:54 2016 from portal.inf.ufrgs.br
locked by user 'vemabaunza' at Wed Aug  3 18:43:52 BRT 2016
-m Victor Martinez - sera liberada 4/08/2016 de manha
Connection to turing closed.

#+end_src

- Quanto aos traces gerados, esses estão na turing, e não os commitei
  para o git por causa do tamanho. Vou fazer uma execução na =turing=
  usando o minibench o que o senhor acha?
  Esse minibench tem mini-aplicações (ideia sugerida pelo Matthias),
  as quais são rápidas de executar, permitindo que o experimento seja
  executado mais rapidamente e que eu possa já na sexta-feira ter um
  volume de trabalho significativo (primeira versão do artigo). Nunca
  trabalhei com o minibench, mas acho uma boa ideia. 

Mensionei o BFS, porque aplicações que utilizam grafos, tendem a ser
memory-bound, pois o índice de cache miss nessas aplicações é muito
alto, visto que o grafo não é armazenado de maneira contínua na
memória é via referência, o processo de busca envolve vários
acessos à memória, podendo gerar vários misses. Depois pensei na Back
Propagation, porque comparado ao BFS, ela é uma aplicação mais
CPU-bound, o que seria interessante analisar nas diferentes fases o
comportamento dessas duas aplicações paralelas. Mas depois, o Matthias
me falou do MiniBench, o que achei interessante e que pode nos ajudar,
o que o senhor acha?

* IEEETran configuration for org export + ignore tag (Start Here)  :noexport:

#+begin_src emacs-lisp :results output :session :exports both
(add-to-list 'load-path ".")
(require 'ox-extra)
(ox-extras-activate '(ignore-headlines))
(add-to-list 'org-latex-classes
             '("IEEEtran"
               "\\documentclass{IEEEtran}"
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
               ("\\paragraph{%s}" . "\\paragraph*{%s}")
               ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+end_src

#+RESULTS:

* *The Paper*                                                       :ignore:
** Latex configurations                                             :ignore:
** Frontpage                                                        :ignore:
#+BEGIN_LaTeX
\title{Measuring Hardware Counters for \\ HPC Application Phase Detection}

\author{
\IEEEauthorblockN{Gabriel Bronzatti Moro, Lucas Mello Schnorr}
\IEEEauthorblockA{Institute of Informatics, Federal University of Rio Grande do Sul \\
Caixa Postal 15064 –- CEP 91501-970 Porto Alegre -- RS -- Brazil\\}
}
#+END_LaTeX

#+LaTeX: \maketitle

** Abstract                                                         :ignore:

#+LaTeX: \begin{abstract}
Besides reducing the execution time of parallel applications, the
power consumption is an increasingly addressed problem in
High-Performance Computing. A parallel program may be composed of
different parallel regions, which can have particular characteristics,
for instance, CPU or memory bound. This paper presents a preliminary
effort to measure performance counters along time to enable the
automatic detection of memory-bound parallel regions. Once attained,
the automatic detection differs from the previous efforts since it
does not require any code instrumentation, making it less intrusive.
Three NAS benchmark parallel applications are used in the experiments:
the Discrete 3D fast Fourier Transform (FT), the Lower-Upper
Gauss-Seidel solver (LU), and the Conjugate Gradient (CG).
As hardware counters, we measure the L2 and L3 cache miss
rate along time using the likwid's timeline mode, a tool to measure
hardware counters from the user space. The experiments enable us 
to identify possible memory-bound code regions by correlating with
changes in cache miss rates. We intend to configure a suitable processor
frequency for each memory-bound parallel region of the application, reducing the
energy consumption of the application with minimal performance loss.
#+LaTeX: \end{abstract}

** Introduction

#+LaTeX: %- Large HPC applications are usually composed by many parallel regions
  #+LaTeX: %- Give some examples
#+LaTeX: %- Each code region has its own memory/cpu/io resource requirements
  #+LaTeX: %- Some might be more memory-bound, others cpu-bound, for example

Large HPC applications are composed of many parallel regions that are
executed by different threads. For example, in an application that
simulates the heat exchange in a metal plate, we could define two
parallel regions: the first to define the initial state of the plate
and another part would be responsible for calculating the heat
exchange in different points of the plate for a number of timesteps.
Each parallel region has its own characteristic, some may be
considered memory-bound, where there is a high rate of the cache miss,
while others may be considered more CPU-bound, with a high instruction
execution rate, others more IO-bound when the thread is limited by
waiting for input or output operations. In the previous example of the
heat plate, one could measure the hardware counters at a given
frequency to define the main characteristic of each parallel region.
An automatic detection of memory-bound parallel regions enable one to
adjust the processor frequency, possibly reducing energy consumption
with minor performance penalties in execution time.

#+LaTeX: %- Automatically detecting such regions could potentially lead to
  #+LaTex: % per-parallel region improvements such as energy and performance
  #+LaTeX: % improvements by adopting an appropriate processor frequency to
  #+LaTeX: % execute



#+LaTeX: %- The idea of this work is to measure hardware counters along time in
#+LaTeX: %  order to correlate their values against the different code region
#+LaTeX: %  - With this information, we intend to detect memory-bound code
#+LaTeX: %    regions that could be potential candidates for energy reduction
#+LaTeX: %    strategies (mainly DVFS)
#+LaTeX: %  - Once the memory-bound code regions have been detected, we intend
#+LaTeX: %    to apply Design of Experiments techniques to find the best
#+LaTeX: %    processor frequency configuration for each region, pretty similar
#+LaTeX: %    to what has been done already lfgmillani2016reppar, but
#+LaTeX: %    automatically.

The main objective of this study is to measure hardware counters at
every given time interval to discover memory-bound code regions.  Once
these regions have been detected, we intend to apply Design of
Experiments screening techniques \cite{jain1991art} to find the best
processor frequency configuration for each region, pretty similar to
what has been done already \cite{millani2016fr}, but
automatically. This paper presents our preliminary results by showing
a time-oriented method to collect hardware counters, using likwid's
timeline mode \cite{treibig2010likwid}.  The preliminary results
indicate that the collected data can possibly enable the automated
identification of memory-bound code regions.

#+LaTeX: %- Paper structure

This paper has the following organization. Section
\ref{sec:relatedwork} presents related work regarding automatic phase
detection for HPC applications. It also motivates our work. Section
\ref{sec:methodology} details our proposal and its corresponding
methodology to fullfill our goal.  Section \ref{sec:results} describes
the platform we have been using to conduct experiments and the
preliminary results we have obtained so far. Section
\ref{sec:conclusion} concludes the paper listing the main
contributions and future work towards automatic detection.

*** Previous structure (in portuguese)                           :noexport:

- contextualizar o problema, relacionando o trabalho já feito pelo
  Luís Felipe, o porque pensar numa detecção automatizada da troca de
  fase entre as threads, o que o trabalho poderá somar ao projeto
  existente.

- apresentar o objetivo do trabalho, o qual será apresentado como um
  "estudo de viabilidade" do trabalho, mostrando que é possível
  realizá-lo técnicamente e que esse é um dos passos fundamentais para
  colocá-lo em prática

- análisar os resultados preliminares

- apresentar a organização do artigo

_Revisão Lucas_

- Cuidar a escrita em português, veja o acento nestas palavras
  - tecnicamente
  - analisar
- 

** Related Work
\label{sec:relatedwork}

#+LaTeX: %- There is no definitive solution to detect if a code region is more
#+LaTeX:  %memory or CPU bound.
#+LaTeX:  %- Usually hard. counters are globally aggregated
#+LaTeX:  %- Automatic techniques usually rely on specific hardware counters

There is no definitive solution to detect if a code region is more
memory or CPU bound. Some works focus more on phase detection to
sequential applications
\cite{spiliopoulos2012power}\cite{laurenzano2011reducing}. Spiliopoulos
et al.\cite{spiliopoulos2012power} present in his work a tool that
analyzes the behavior of a sequential application by detailed analysis
of its execution phases, based on cache misses of the different
levels of cache \review{Could you please be more precise?}, the tool identifies the best processor frequency to
be used in each phase to best performance and reduce energy
consumption
\review{What is the problem of doing only for sequential applications?}.
In addition to this approach, Laurenzano et
al.\cite{laurenzano2011reducing} present an approach finer granularity
for identifying the most appropriate processor frequency for each
application loop. From the executions, it is defined a model of multiple
dimensions that allows one to find given loop frequency that best defines the
behavior of energy and expected performance
\review{Impossible to understand this last phrase.}.

There is also investigation to consider MPI or OpenMP parallel
applications. Freeh et al.\cite{freeh2005exploring} present an
approach to define the most suitable frequency for each phase of an
MPI application. Among the available frequencies, the approach looks
at what is the best frequency for a given node operate during the
execution of the application.  Another approach \cite{millani2016fr},
focused in OpenMP applications, analyzes the parallel regions of a
program using a rigorous evaluation using design of experiments and
screening designs.  According to their analysis based on seven
benchmarks, it is possible to reach a considerable gain in energy
reduction, eventually with no performance loss, depending on the
characteristics of the benchmark.  Their approach use manual
instrumentation to identify the code regions that are going to be
analzed. We focus instead in the automatic detection of such regions
based on hardware counters. In this paper we show our investigation in
how these counters can be measured along the application execution.

The next section describes our measurement and evaluation methodology
to collect hardware counters at a given frequency.

** Measurement and Evaluation Methodology
\label{sec:methodology}

The methodology used in the work first defines the compilation a
source code into binary. The program is run under the likwid-perfctr
tool that allows you to collect hardware counters for each processing
core. The data is processed by a script tailored to generate a
detailed application trace to carry out the data analysis. The Figure
\ref{figMetodologia} shows an overview of the methodology with all
such steps.

#+LaTeX: \begin{figure}[!htb] \label{figMetodologia}
#+LaTeX:   \caption{Overview of the methodology. \review{binary, grouping script (passe o corretor com aspell). Tua figura não ocupa todo o espaço horizontal disponível, acho que deveria. Ela faz um círculo no sentido anti-horário. Acho que deveria ser mais linear.}}
#+LaTeX:    \centering \includegraphics[width=5cm,height=6cm]{img/metodologiaWorkWsppd2016.pdf}
#+LaTeX: \end{figure}

We employ such methodology in three NAS Parallel applications: the 3D
Discrete Fast Fourier Transform (FT), the Lower-Upper Gauss-Seidel
Solver (LU) and the Conjugate Gradient (CG). The choice is because
they present very different behaviors in L2 and L3 miss rate when
compared to other applications of the benchmark.
\review{Não é o que dá para ver nos gráficos a seguir.}
The applications are executed with 32 threads using the input size
(class B) of the NAS benchmark. The execution platform used is a
Workstation with 2 processors Intel (R) Xeon (R) E5-2650 CPU 2.00 GHz,
each with 8 physical cores and Hyper-Threading technology.

The hardware counters are collected using likwid's timeline mode
\cite{treibig2010likwid}, configured to measure L2 and L3 cache miss
rate at a given time interval. Such interval between each metric
recording is defined according to the total execution time of each
application. For example, in the FT application, the measurement
period is defined as 30 milliseconds, generating about 172 samples
(for each of the 32 threads). For the LU application a 100
milliseconds is adopted, for about 363 samples. For CG, a period of 50
milliseconds for about 384 samples. According to the likwid authors,
adopting a period less than 100 milliseconds might generate non-valid
results. Even so, the global behavior is still valid if one aggregate
such information along time. We report FT and CG results under this
limitation in order to investigate how frequent measurements impact
our analysis of phase detection.

** Preliminary Results
\label{sec:results}

We present the L2 and L3 cache miss rate considering the aggregated
metrics for all cores of the two processors where we conducted
experiments. Points in the plots represented such aggregated values,
while lines are there only to show the metric trend along
time. Despite the fact that we aggregated values, we have looked to
each core cache level miss and they are all similar and homogeneous
(because of the regular nature of the applications we used),
justifying such aggregation to simplify the analysis.


The execution of the FT application (Figure x) shows that for the l2
cache there is a homogeneous behavior of the rate of misses during
execution of the application. The highest rate found in implementation
of FT was 31% between 7.5 to 10 seconds late time execution. Already
the lowest rate was found about 6% of missions in seconds of
execution. Regarding the behavior of the CPUs it is possible to see that
there is a closeness between the lines graphic, it may be related to
the application has a good load balancing between threads. Some points
have the disparity between the misses behavior of CPUs, as We are
analyzing the L2 cache level should take into account the
characteristic of the execution platform where the experiment was
executed, which is NUMA (Non-Uniform Memory Access to) and can
influence such behavior. 

#+BEGIN_LaTeX
\begin{figure}[!htb]
\includegraphics[width=\linewidth]{img/ft_L2_L3_30ms.pdf}
\caption{The L2 and L3 cache miss rate of the Discrete 3D Fast Fourier Transform (NAS-FT, Class B) when measuring metrics every 30 milliseconds.}
\label{figFT}
\end{figure}
#+END_LaTeX

Besides, it is possible can see that the application for the FT L3
cache level has a higher rate of misses equal to 37% at the beginning
of the application. The higher rate of 37% of the L3 cache misses may
be associated with the same timestamp occurred in the L2 cache, which
can be seen in the range of 0 to 2.5 seconds. The behavior of the miss
rate in the L3 cache is particular, the graph shows a linear range of
the different peaks where occurs more misses, the peaks will decrease
throughout the execution. Also, we visualize in this graph (as in the
L2 cache) that the two CPUs have a similar behavior.


#+LaTeX: \begin{figure}[htp]\label{figLU}
#+LaTeX:  \centering \includegraphics[width=8cm,height=8cm]{img/luBNas_Analise.pdf}
#+LaTeX:  \centering \includegraphics[width=8cm,height=8cm]{img/luBNas_Analise_l3.pdf}
#+LaTeX: \caption{Execution of the Lower-Upper Gauss-Seidel solver.}
#+LaTeX: \end{figure}

In the application LU it is possible to see that for the L2 cache, the
graph (Figure \ref{figLU}) has a more amorphous behavior, different from misses
behavior for the FT application (Figure \ref{figFT}). In some execution points,
CPUs have a different behavior in misses of the L2 cache. Most misses
rate in L2 for this application was 13% in the first seconds of
running the application, already the lowest rate is less than 1% and
occurs late in the range of 30 to 40 seconds of execution. 

The behavior of the LU application misses rate in the L3 cache has the
highest occurrence identified in the first seconds of execution, about
13% of cache misses, the same timestamp that occurs first peak in
missions behavior in L2. Already identified the smallest rate was
about 0.07% of misses after 36 seconds. The two CPUs had a more
similar behavior in this graphic can be observed a little difference
between their miss rates at the beginning of execution and also
between the range and 20 and 30 seconds.  

#+LaTeX: \begin{figure}[htp]\label{figCG}
#+LaTeX:  \centering \includegraphics[width=8cm,height=8cm]{img/cgBNas_Analise.pdf}
#+LaTeX:  \centering \includegraphics[width=8cm,height=8cm]{img/cgBNas_Analise_l3.pdf}
#+LaTeX: \caption{Execution of the Conjugate Gradient.}
#+LaTeX: \end{figure}


Figure \ref{figCG} shows the misses rate for CG application in L2 cache, it is
possible to see that at the beginning of implementation there is a
considerable increase in cache misses rate after this peak rate
remains linearly. The highest value was identified for when the
application reached 23 seconds of execution, about 38% higher value
than other applications for L2 cache, which may be related to the
application characteristics, which has irregular access memory,
different from other applications. The lowest index cache misses was
identified earlier in the application, about 10%. As for the L3 cache,
it is possible to identify an increase in cache misses rate at the
beginning of the application, about 23% after its behavior is linear.

** Conclusion
\label{sec:conclusion}


The results show cache misses rate results for the L2 cache and also
to the L3 cache. From this result, it is possible to define the most
memory-bound regions, which have a rate of cache misses larger than
the other, as well as more CPU-bound regions that have smaller cache
misses rates. In our experiment, where were performed the FT
applications (3D Discrete Fast Fourier Transform), LU (Lower-Upper
Gauss-Seidel solver) and Conjugate Gradient (CG) is possible see which
applications are more memory-bound than the other and in which parts
of its execution, they are more memory-bound.

Not all tools offer adequate support to collect counters in hardware
small time intervals (msec range), the tool used (likwid) provided the
values of the respective counters hardware of time slices requested
timestamp defined in the experiments, allowing examine other
characteristics to define memory-bounds areas of a parallel
application. 

The next step of the work consists of the following steps: explore
other measures to define with greater accuracy the memory-bound
regions, align the technique of Design of Experiments in our
methodology and use the DVFS application for efficiency energy and
higher performance for applications specifically identified in the
parallel memory-bound regions. 


#+LATEX: \section*{Acknowledgements}

This research receives HPC-ELO project funds, the H2020
program EU and MCTI / RNP-Brazil through HPC4E project
with code 689772

#+LaTeX: %Who paid for this?

** References                                                        :ignore:

# See next section to understand how refs.bib file is created.

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{refs}

* Bib file is here                                                 :noexport:

Tangle this file with C-c C-v t

#+begin_src bib :tangle refs.bib

@inproceedings{freeh2005exploring,
  title={Exploring the energy-time tradeoff in mpi programs on a power-scalable cluster},
  author={Freeh, Vincent W and Pan, Feng and Kappiah, Nandini and Lowenthal, David K and Springer, Robert},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium},
  pages={4a--4a},
  year={2005},
  organization={IEEE}
}

@inproceedings{laurenzano2011reducing,
  title={Reducing energy usage with memory and computation-aware dynamic frequency scaling},
  author={Laurenzano, Michael A and Meswani, Mitesh and Carrington, Laura and Snavely, Allan and Tikir, Mustafa M and Poole, Stephen},
  booktitle={European Conference on Parallel Processing},
  pages={79--90},
  year={2011},
  organization={Springer}
}

@inproceedings{spiliopoulos2012power,
  title={Power-Sleuth: A Tool for Investigating Your Program's Power Behavior},
  author={Spiliopoulos, Vasileios and Sembrant, Andreas and Kaxiras, Stefanos},
  booktitle={2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},
  pages={241--250},
  year={2012},
  organization={IEEE}
}

@incollection{schnorr2013visualizing,
  title={Visualizing More Performance Data Than What Fits on Your Screen},
  author={Schnorr, Lucas M and Legrand, Arnaud},
  booktitle={Tools for High Performance Computing 2012},
  pages={149--162},
  year={2013},
  publisher={Springer}
}

@inproceedings{millani2016fr,
author = {Millani, Luis Felipe and Schnorr, Lucas Mello},
title={Computation-Aware Dynamic Frequency Scaling: Parsimonious Evaluation of the Time-Energy Trade-off Using Design of Experiments},
year={2016},
booktitle={3rd International Workshop on Reproducibility in Parallel Computing (REPPAR)}
}

@book{jain1991art,
  title={Art of Computer Systems Performance Analysis: Techniques For Experimental Design Measurements Simulation and Modeling},
  author={Jain, R.},
  isbn={9781118858424},
  year={1991},
  publisher={Wiley}
}

@inproceedings{treibig2010likwid,
  title={Likwid: A lightweight performance-oriented tool suite for x86 multicore environments},
  author={Treibig, Jan and Hager, Georg and Wellein, Gerhard},
  booktitle={2010 39th International Conference on Parallel Processing Workshops},
  pages={207--216},
  year={2010},
  organization={IEEE}
}

#+end_src
* 2016-08-20 New plots                                             :noexport:

#+begin_src R :results output graphics :file img/ft_L2_L3_30ms.pdf :exports both :width 6 :height 3 :session
library(dplyr);
df2 <- read.csv("../../dados/exp1_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
df2 <- df2[df2$Metric == "M7", ];
df2$Metric <- "L2";
df3 <- read.csv("../../dados/exp2_NASandLikwid/ftB.csv", sep=" ", strip.white=T);
df3 <- df3[df3$Metric == "M7", ];
df3$Metric <- "L3";
df <- rbind (df2, df3);
df$Application <- "FT";
g <- df %>% group_by(Time,Metric,Application) %>% summarize (N=n(), mean=mean(Value)*100) %>% as.data.frame();

library(ggplot2);
ggplot(g, aes(x=Time, y=mean,color=as.factor(Metric))) +
  	geom_line(size=0.5) + geom_point(size=1) + theme_bw() + ylim(0,50) +  
     theme(legend.position=c(0.9,0.8),
               legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
     scale_color_discrete(name="Cache Level") + facet_wrap(~Application) +
      labs(x = "Runtime (seconds)", y= "Average Cache Misses (%)");

#+end_src

#+RESULTS:
[[file:img/ft_L2_L3_30ms.pdf]]

