#+TITLE: LabBook
#+AUTHOR: Gabriel Bronzatti Moro and Lucas M. Schnorr
#+LATEX_HEADER: \usepackage[margin=2cm,a4paper]{geometry}
#+STARTUP: overview indent
#+TAGS: Gabriel(G) Lucas(L) noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)
#+mode: org
#+coding: utf-8

Esse documento está em pt-br

* [00:18:39; 02.07.2016] Tarefas da Primeira Reunião com o Professor Lucas :Gabriel:
** Principais trabalhos relacionados - Artigo do Luis Felipe

|---------------------+---------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------|
| *Autores*             | *Título*                                                                                            | *Objetivo*                                                                                                                                                     | *Metodologia*                                                                                                                                                                                                                 | *Benchmark, Ferramenta ou Tecnologia*                                | *Resultados*                                                                                                                                                                                                              | *Observação*                                                                                                                                                                       | *Diferença do nosso trabalho*                                      |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|---------------------+---------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------|
| Laurenzano et al.   | =Reducing energy usage with memory and with memory and computation-aware dynamic frequency scaling= | - Abordagem que permite selecionar *por laço* a melhor frequência de clock. O critério de frequência mais adequado está entre desempenho e consumo de energia. | - Instrumentação realizada através da utilização da ferramenta PEBIL toolkit                                                                                                                                                | - Benchmark própio =pcubed= (PMaC's Performance and Power benchmark) | - Os principais resultados adquiridos pelos autores foi a economia de cerca de 7,6% de energia para a primeira plataforma de execução (Intel Xeon E5530) e para a segunda plataforma (AMD Opteron 8380) cerca de 10,6%. | - O autor não chega a definir, mas menciona que uma aplicação =memory-bound= depende primeiramente da proximidade, tamanho e do Speedup disponível com as operaçoes sob a memoria. | - Foco em aplicações paralelas\ (OpenMP)                         |
|                     |                                                                                                   |                                                                                                                                                              | - Uso da biblioteca cpu-freq para alterar a frequência do processador                                                                                                                                                       |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  | - Regiões paralelas dentro da abordagem fork-join                |
|                     |                                                                                                   |                                                                                                                                                              | - Experimento: os parâmentos levados em consideração para aplicação são: taxa de hit dos diferentes níveis de cache, operações de ponto-flutuante (FP) sob a memória e a media de computação de operações sob FP e inteiro. |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              | - A plataforma de execução escolhida por eles *permite a alteração da frequência independentemente de cada core* (frequências avaliadas no experimento 1.6, 1.73, 1.86, 2, 2.13, 2.26, 2.39 e 2.40 GHz).                      |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|---------------------+---------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------|
| Freeh et al.        | =Using Multiple Energy Gears in MPI Programs on a Power-Scalable Cluster=                           | - Abordagem que tem por objetivo encontrar a *frequência adequada para cada fase da aplicação MPI*, de acordo com a heurística alvo (energia e/ou desempenho). | - A aplicação é dividida em n fases e diferentes gears (microprocessadores), para cada gear é executado as n fases da aplicação                                                                                             | - Benchmark do =NAS=                                                 | - Os resultados apresentam a partir da combinação adequada de frequências para os benchmarks executados é possível obter um bom ganho de energia caso fosse utilizado apenas a mesma frequência nos diferentes nós.     | - Os autores introduzem a métrica =OPM (Operations per Miss)=, a qual permite verificar a pressão de memória de uma aplicação ou de uma fase.                                      | - Foco em aplicações paralelas de memória compartilhada (OpenMP) |
|                     |                                                                                                   |                                                                                                                                                              | - Resultados obtidos de tempo e energia                                                                                                                                                                                     |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  | - Trabalho concentra-se em apenas um nó                          |
|                     |                                                                                                   |                                                                                                                                                              | - O cluster aonde foi executado os experimentos permitia a configuração de até 10 diferentes frequências.                                                                                                                   |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|                     |                                                                                                   |                                                                                                                                                              |                                                                                                                                                                                                                             |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|---------------------+---------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------|
| Spiliopoulos et al. | =Power-Sleuth: A Tool for Investigating your Program's Power Behavior=                              | - Melhorar o desempenho e o consumo de energia alterando as frequências por fase da aplicação.                                                               | - Aplicação dividida em fases, durante a execução são coletadas informações sobre essas fases para estimar o consumo de energia de cada fase.                                                                               | - ScarPhase para caracterizar cada fase da aplicação               | - Os resultados do artigo permitem analisar apenas a acurácia da ferraemnta com as medidas de potência reais                                                                                                            |                                                                                                                                                                                  | - Foco em aplicações paralelas                                   |
|                     |                                                                                                   |                                                                                                                                                              | - Após a análise do comportamento da execução a ferramenta desenvolvida pelos autores é capaz de alternar a frequência de cada fase para melhorar o consumo de energia e o desempenho                                       |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  | - Nossa divisão do programa é em regiões e não fases             |
|                     |                                                                                                   |                                                                                                                                                              | - A abordagem utiliza um modelo de desempenho DVFS, um modelo de correlação de capacitânciae uma técnica para detectar as fases da aplicação.                                                                               |                                                                    |                                                                                                                                                                                                                         |                                                                                                                                                                                  |                                                                  |
|---------------------+---------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------|

- Alguns trabalhos possíveis: 

*** Caracterização de aplicações paralelas implementadas em OpenMP
	=Motivativação=: Análise do comportamento da aplicação paralela
	via contadores de hardware. A partir disso será possível
	visualizar o perfil de execução da aplicação pelos contadores
	de hardware. A técnica pode ser usada como uma pré-execução.

	=Metodologia=: Uso da abordagem =DoE= (Desing of Experiments) para
	projetar o experimento e analisar os resultados. Freeh et
	al. possui um trabalho similar, mas o diferencial do nosso
	trabalho é a metodologia e o uso da técnica DoE.
        
*** Modelagem de energia para aplicações híbridas OpenMP/MPI
	=Motivativação=: Contabilizar a energia gasta em cada regiÃ£o
	paralela, mas também a energia gasta dentro do nó (intra-node)
	e a comunicação dentro do nó (se existir) e a comunicação fora
	do nó. Esse trabalho se concentraria na estimativa da energia
	total gasta pela aplicação híbrida implementada em
	OpenMP/MPI.

	=Metodologia=: A metodologia pode ser a seguinte (uma abordagem
	button-up):
        a) Estimar a energia de cada região paralela (usando
           contadores de hardware em diferentes nós);
        b) Estimar a energia da aplicação (fora do limite fork-join);
        c) Estimar a energia da aplicação na comunicação intra-nó;
        d) Estimar a energia da comunicação inter-node (fora do nó).

  =Results=: O resultado seria a estimativa de energia da aplicação
  híbrida como um todo e também a energia gasta em cada nó. Isso pode
  oferecer uma estimativa correta de energia para essas aplicações, a
  partir da informação obtida o desenvolvedor poderá otimizar alguma
  parte da sua aplicação.
* [19:10:05; 05.07.2016] Reunião Semanal com o Professor Lucas :Gabriel:Lucas:
** Definição do assunto da dissertação
	=Objetivo=: Detectar as fases da aplicação utilizando contadores
	de hardware.

    =Ferramentas a serem investigadas=: ScoreP (com PAPI), ExtraE e
    TAU. Também procurar como realizar uma medição utilizando
    contadores de hardware along time.

    =Tarefas=: 
    	a) fazer os trabalhos relacionados direcionando-os na
    temática ``Parallel Application Phase Detection'';
    	b) implementar a detecção de fase usando contadores do PAPI +
           ScoreP;
       	    b.1) A parte =along_time=
		c) Definir as fases, aplicar conhecimento para reduzir energia
    
* [22:15:57; 08.07.2016] Configuração de Ambiente Scorep e PAPI     :Gabriel:
** Instalação do PAPI
#+begin_src sh :results output :exports both
cd $HOME/Downloads/
wget http://icl.cs.utk.edu/projects/papi/downloads/papi-5.4.3.tar.gz
tar -vzxf papi-5.4.3.tar.gz
cd papi-5.4.3/src/
./configure
make
sudo make install
#+end_src

- Verificando se a instalação foi realizada com sucesso

#+begin_src sh :results output :exports both
cd /usr/local/lib/
ls | grep -i libpapi
#+end_src

#+RESULTS:
: libpapi.a
: libpapi.so
: libpapi.so.5
: libpapi.so.5.4.3
: libpapi.so.5.4.3.0

#+begin_src sh :results output :exports both
cd /usr/local/include/
ls | grep -i papi.h
#+end_src

#+RESULTS:
: f77papi.h
: f90papi.h
: fpapi.h
: papi.h

** Instalação do Scorep

- Um dos pré-requisitos de instalação do Scorep e a instalação do
  =Qt_app=.

#+begin_src sh :results output :exports both
cd $HOME/Downloads/
wget http://download.qt.io/official_releases/online_installers/qt-unified-linux-x64-online.run
./qt-unified-linux-x64-online.run
#+end_src

#+RESULTS:

#+begin_src sh :results output :exports both
cd $HOME/Programs/
wget http://www.vi-hps.org/upload/packages/scorep/scorep-2.0.2.tar.gz
tar -vxf scorep-2.0.2.tar.gz
rm scorep-2.0.2.tar.gz
cd scorep-2.0.2/
./configure --prefix=$HOME/Programs/scorep-2.0.2/ --enable-papi  --with-papi-lib=/usr/local/lib/ --with-papi-header=/usr/local/include/
make
sudo make install
#+end_src

#+RESULTS:

#+BEGIN_EXAMPLE

#+END_EXAMPLE

- Compilando aplicação com OpenMP com Scorep

#+begin_src sh :results output :exports both
cd benchmarks/MM/
$HOME/Programs/scorep-2.0.2/bin/scorep gcc -fopenmp -O2 hpcelo.c continuos.c -o continuos_sp
ls
#+end_src

#+RESULTS:
#+begin_example
continuos.c
continuos_sp
continuosT.c
hpcelo.c
hpcelo.h
Makefile
normal.c
normalT.c
tiling.c
tilingT.c
#+end_example

- Habilitando o trace para a execução da aplicação:

#+begin_src sh :results output :exports both
cd benchmarks/MM/
export SCOREP_ENABLE_PROFILING=true
export SCOREP_ENABLE_TRACING=true
export SCOREP_TOTAL_MEMORY=2G
export SCOREP_METRIC_PAPI=
export SCOREP_METRIC_PAPI_PER_PROCESS=PAPI_L1_TCA,PAPI_L2_TCA
export SCOREP_METRIC_RUSAGE_PER_PROCESS=all
export SCOREP_MEMORY_RECORDING=true
export SCOREP_EXPERIMENT_DIRECTORY=continuosExecution 
./continuos_sp 1000
ls
#+end_src

#+RESULTS:
#+begin_example
HPCELO:1.065932
continuos.c
continuosExecution
continuos_sp
continuosT.c
hpcelo.c
hpcelo.h
Makefile
normal.c
normalT.c
tiling.c
tilingT.c
#+end_example
* [16:22:11; 14.07.2016] Conversa semanal com Gabriel         :Gabriel:Lucas:

Com relação a entrada:
- [[*DefiniÃ§Ã£o do assunto da dissertaÃ§Ã£o][Definição do assunto da dissertação]]

Rastreamento com scorep 2.0.2, configurado da seguinte maneira:

#+BEGIN_EXAMPLE
./configure --prefix=/home/schnorr/install/scorep-2.0.2/ --enable-papi  --with-papi-lib=/usr/local/lib/ --with-papi-header=/usr/local/include/
#+END_EXAMPLE

Na saída do config.log, temos:

#+BEGIN_EXAMPLE
(...)
    Score-P (backend):
      C99 compiler used:        gcc
      Pthread support:          yes, using gcc -pthread 
      compiler constructor:     yes, using attribute syntax
      TLS support:              yes, using __thread
      PAPI support:             yes
      metric perf support:      yes
      Unwinding support:        yes
        libunwind support:      yes, using -D_GNU_SOURCE -lunwind
      Sampling support:         yes, using -D_GNU_SOURCE, sa_sigaction
      getrusage support:        yes
      RUSAGE_THREAD support:    yes, using -D_GNU_SOURCE
      dlfcn support:            yes, using -ldl
(...)
#+END_EXAMPLE

Depois de configurar as seguintes variáveis de ambiente:

#+BEGIN_EXAMPLE
export SCOREP_ENABLE_TRACING=true
export SCOREP_METRIC_PAPI=PAPI_L1_TCM
#+END_EXAMPLE

O programa foi executado com =sudo -E=. O argumento =-E= foi importante
para que as variáveis de ambiente do shell corrente sejam transferidas
para o shell que o sudo criará para lançar a aplicação. Precisamos
utilizar =sudo= pois a aplicação necessita acessar contadores de
hardware que são capazes de ser lidos pelo superusuário. Uma forma
melhor de fazer isto é utilizar =setcap=.

Depois de executar o programa que foi compilado com =scorep gcc=,
podemos ver a evolução da métrica =PAPI_L1_TCM= ao longo do tempo
através do seguinte comando:
- a terceira coluna é o timestamp onde o valor da métrica foi
  observado
- o valor da métrica aparece depois do UINT64

No caso de =PAPI_L1_TCM= o valor da métrica é a quantidade de vezes que
ocorreu cache miss na cache L1.

#+BEGIN_EXAMPLE
schnorr@guarani:~/svn/hpcelo-gabriel/MM/src$ /home/schnorr/install/scorep-2.0.2/bin/otf2-print scorep-20160714_1559_2932482742715837/traces.otf2 | grep 12884901888 | grep METRIC
METRIC                           12884901888     2932482706525714  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 571)
METRIC                           12884901888     2932482706534678  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 776)
METRIC                           12884901888     2932482732253601  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 930)
METRIC                           12884901888     2932482732318445  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 1119)
METRIC                           12884901888     2932482732323234  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 1181)
METRIC                           12884901888     2932482732325389  Metric: 0, 1 Values: ("PAPI_L1_TCM" <8>; UINT64; 1192)
...
#+END_EXAMPLE

Quais são os contadores que devem ser medidos?
- Difícil responder, primeiro precisamos investigar quais contadores
  poderiam (no caso de valores altos) representar uma aplicação
  CPU-bound e uma aplicação MEMORY-bound.
- Procurar na literatura artigos que consigam definir uma eventual
  relação que exista entre CPU-bound e determinados contadores de
  hardware (e o equivalente para algo MEMORY-bound)

Tarefas:
- Medir ao longo do tempo e com scorep o máximo possível de contadores
  - Eventualmente todos os contadores disponíveis
- Utilizar a aplicação de MM desenvolvida por ti
* [23:39:31; 14.07.2016] Execução do benchmark MM com PAPI via Scorep :Gabriel:

- Compilação, utilizando o make file com a diretiva =scorep gcc=:

#+begin_src sh :results output :exports both
cd benchmarks/MM/
make
ls
#+end_src

#+RESULTS:
#+begin_example
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o normal_seq.o -c normal.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o normal_seq hpcelo.c normal_seq.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o normal_par.o -c normal.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o normal_par hpcelo.c normal_par.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o continuos_seq.o -c continuos.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o continuos_seq hpcelo.c continuos_seq.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o continuos_par.o -c continuos.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o continuos_par hpcelo.c continuos_par.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o tiling_seq.o -c tiling.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o tiling_seq hpcelo.c tiling_seq.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o tiling_par.o -c tiling.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o tiling_par hpcelo.c tiling_par.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o normal_seqT.o -c normalT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o normal_seqT hpcelo.c normal_seqT.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o normal_parT.o -c normalT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o normal_parT hpcelo.c normal_parT.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o continuos_seqT.o -c continuosT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o continuos_seqT hpcelo.c continuos_seqT.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o continuos_parT.o -c continuosT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o continuos_parT hpcelo.c continuos_parT.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o tiling_seqT.o -c tilingT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -o tiling_seqT hpcelo.c tiling_seqT.o
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o tiling_parT.o -c tilingT.c
/home/gbmoro/Programas/scorep-2.0.2/bin/scorep gcc -Wall -Wextra -O2 -fopenmp -o tiling_parT hpcelo.c tiling_parT.o
continuos.c
continuos_par
continuos_par.o
continuos_parT
continuos_parT.o
continuos_seq
continuos_seq.o
continuos_seqT
continuos_seqT.o
continuosT.c
hpcelo.c
hpcelo.h
Makefile
normal.c
normal_par
normal_par.o
normal_parT
normal_parT.o
normal_seq
normal_seq.o
normal_seqT
normal_seqT.o
normalT.c
tiling.c
tiling_par
tiling_par.o
tiling_parT
tiling_parT.o
tiling_seq
tiling_seq.o
tiling_seqT
tiling_seqT.o
tilingT.c
#+end_example

#+begin_src sh :results output :exports both
cd benchmarks/MM/
export SCOREP_ENABLE_TRACING=true
export SCOREP_TOTAL_MEMORY=2G
export SCOREP_METRIC_PAPI=PAPI_L1_DCM,PAPI_L1_ICM,PAPI_L2_DCM
export SCOREP_METRIC_RUSAGE=ru_utime,ru_stime
export SCOREP_EXPERIMENT_DIRECTORY=exec1
./normal_parT 100
cd exec1/
/$HOME/Programas/scorep-2.0.2/bin/otf2-print traces.otf2
#+end_src

#+RESULTS:
#+begin_example

=== OTF2-PRINT ===
=== Events =====================================================================
Event                               Location            Timestamp  Attributes
--------------------------------------------------------------------------------
METRIC                                     0       79633289900948  Metric: 0, 5 Values: ("PAPI_L1_DCM" <8>; UINT64; 2890), ("PAPI_L1_ICM" <9>; UINT64; 7001), ("PAPI_L2_DCM" <10>; UINT64; 1770), ("ru_utime" <11>; UINT64; 4000), ("ru_stime" <12>; UINT64; 12000)
ENTER                                      0       79633289900948  Region: "main" <16>

#+end_example

* DONE [09:25:09; 15.07.2016] Criação do script para execução do benchmark MM com PAPI via Scorep :Gabriel:

- State "DONE"       from "STARTED"    [2016-07-15 Sex 20:35]
- State "STARTED"    from              [2016-07-15 Sex 10:14]
#+begin_src sh :results output :exports both :tangle benchmarks/MM/scriptSimulation.bash
#!bin/bash

apps=( 
    "continuos_par" 
    "continuos_parT" 
    "normal_par" 
    "normal_parT" 
    "tiling_par" 
    "tiling_parT" 
)

inputSizes=( 
    50 
    60 
    80 
    100 
)

export SCOREP_ENABLE_TRACING=true
export SCOREP_METRIC_PAPI=PAPI_L1_DCM,PAPI_L1_ICM,PAPI_L1_TCM,PAPI_L2_DCM,PAPI_L2_ICM,PAPI_L2_TCM,PAPI_L2_ICA,PAPI_L3_ICA
export SCOREP_METRIC_RUSAGE=ru_utime,ru_stime


for j in ${apps[@]}
do 
  for i in ${inputSizes[@]}
  do
    echo "Running app: $j size: $i"
    export SCOREP_EXPERIMENT_DIRECTORY="exec_$jsize$i"
    sudo -E ./$j $i
  done
done

#+end_src

O script de execução está rodando corretamente, os contadores PAPI
utilizados foram escolhidos de acordo com a disponibilidade da minha
máquina pessoal. Estou com problemas apenas na execução do algoritmo
=tiling=, isso Ã© porque o mesmo utiliza muito a memória principal para
otimizar o uso da cache. O erro que está acontecendo com o SCOREP é o
seguinte:

#+BEGIN_EXAMPLE
Running app: tiling_par size: 60
[Score-P] Trace buffer flush on rank 0.
[Score-P] Increase SCOREP_TOTAL_MEMORY and try again.
[Score-P] Trace buffer flush on rank 0.
[Score-P] Increase SCOREP_TOTAL_MEMORY and try again.
[Score-P] Trace buffer flush on rank 0.
[Score-P] Increase SCOREP_TOTAL_MEMORY and try again.
[Score-P] Trace buffer flush on rank 0.
[Score-P] Increase SCOREP_TOTAL_MEMORY and try again.
[Score-P] Trace buffer flush on rank 0.
[Score-P] Increase SCOREP_TOTAL_MEMORY and try again.
HPCELO:0.462356
#+END_EXAMPLE

- Vou mudar o script para aumentar o =SCOREP_TOTAL_MEMORY=:

#+begin_src sh :results output :exports both :tangle benchmarks/MM/scriptSimulation2.bash
#!bin/bash

apps=( 
    "continuos_par" 
    "continuos_parT" 
    "normal_par" 
    "normal_parT" 
    "tiling_par" 
    "tiling_parT" 
)

inputSizes=( 
    50 
    60 
    80 
    100 
)

export SCOREP_ENABLE_TRACING=true
export SCOREP_TOTAL_MEMORY=3G
export SCOREP_PAGE_SIZE=800000
export SCOREP_METRIC_PAPI=PAPI_L1_DCM,PAPI_L1_ICM,PAPI_L1_TCM,PAPI_L2_DCM,PAPI_L2_ICM,PAPI_L2_TCM,PAPI_L2_ICA,PAPI_L3_ICA
export SCOREP_METRIC_RUSAGE=ru_utime,ru_stime


for j in ${apps[@]}
do 
  for i in ${inputSizes[@]}
  do
    echo "Running app: $j size: $i"
    export SCOREP_EXPERIMENT_DIRECTORY="exec_$jsize$i"
    sudo -E ./$j $i
  done
done

#+end_src

Executando o script com a modificação no =SCOREP_TOTAL_MEMORY= para 3
gigabytes, ocorreu o seguinte erro:

#+BEGIN_EXAMPLE
[Score-P] Please report this to support@score-p.org. Thank you.
[Score-P] Try also to preserve any generated core dumps.
^CRunning app: tiling_parT size: 60
[Score-P] src/measurement/SCOREP_Memory.c:106: Fatal: Bug '!allocator': Cannot create memory manager for SCOREP_TOTAL_MEMORY=3221225472 and SCOREP_PAGE_SIZE=800000
#+END_EXAMPLE

Esse erro de acordo com os fÃ³runs Ã© devido a minha limitaÃ§Ã£o de
memÃ³ria principal. 

- Vou modificar o script para executar todos os algoritmos de
  multiplicação de matriz, exceto o =tiling=.

#+begin_src sh :results output :exports both :tangle benchmarks/MM/scriptSimulation3.bash
#!bin/bash

apps=( "continuos_par" "continuos_parT" "normal_par" "normal_parT" )

inputSizes=( 50 60 80 100 )

export SCOREP_ENABLE_TRACING=true
export SCOREP_METRIC_PAPI=PAPI_L1_DCM,PAPI_L1_ICM,PAPI_L1_TCM,PAPI_L2_DCM,PAPI_L2_ICM,PAPI_L2_TCM,PAPI_L2_ICA,PAPI_L3_ICA
export SCOREP_METRIC_RUSAGE=ru_utime,ru_stime


for j in ${apps[@]}
do 
  for i in ${inputSizes[@]}
  do
          export SCOREP_EXPERIMENT_DIRECTORY="exec_$j$i"
	    echo "Running app: $j size: $i"
	    sudo -E ./$j $i
  done
done

#+end_src

As pastas geradas foram:

#+begin_src sh :results output :exports both
cd benchmarks/MM/
ls | grep -i exec
#+end_src

#+RESULTS:
#+begin_example
exec_continuos_par100
exec_continuos_par50
exec_continuos_par60
exec_continuos_par80
exec_continuos_parT100
exec_continuos_parT50
exec_continuos_parT60
exec_continuos_parT80
exec_normal_par100
exec_normal_par50
exec_normal_par60
exec_normal_par80
exec_normal_parT100
exec_normal_parT50
exec_normal_parT60
exec_normal_parT80
#+end_example

O próximo passo é fazer um script para analisar esses dados e a partir
deles gerar um arquivo csv. Esse script deverá utilizar a saída da
ferramenta =otf2print= disponibilizada pelo =scorep=.
* WAITING [00:09:15; 16.07.2016] Análise dos resultados do experimento com PAPI - benchmark MM :Gabriel:
- State "WAITING"    from "STARTED"    [2016-07-18 Seg 12:07]
- State "STARTED"    from              [2016-07-16 SÃ¡b 14:24]

** Exportando o arquivo csv por thread
Primeiramente vou fazer um script teste para gerar o csv do arquivo
gerado na execução da versão =normal_par= com =80= de entrada. O script
vai ser criado em python, porque como são muitos dado

#+begin_src sh :results output :exports both
cd benchmarks/MM/exec_normal_par80/
/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | awk '{ print $1,$2,$3,$4,$5,$8,$11,$12,$15,$16,$19,$20,$21,$24,$27,$28,$31 }' >> t.csv
#+end_src

#+RESULTS:

#+begin_src sh :results output :exports both
cd benchmarks/MM/exec_normal_par80/
sudo /home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | awk '{ print $1,$2,$3,$4,$5,$8,$11,$12,$15,$16,$19,$20,$21,$24,$27,$28,$31 }' >> t.csv
#+end_src

#+RESULTS:
|sh: 2: cannot create t.csv: Permission denied|

#+begin_src sh :results output :exports both
cd benchmarks/MM/
chmod 777 exec*
#+end_src

#+RESULTS:

- Vou tentar novamente com as permissões alteradas

#+begin_src sh :results output :exports both
cd benchmarks/MM/exec_normal_par80/
 /home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | sed 's/(//g' | sed 's/)//g' | sed 's/\"P/P/g' | sed 's/\"/,/g' | sed 's/C[[:space:]]/C,/g' | sed 's/[[:space:]]M/,M/g' | sed 's/[[:space:]]R/,R/g'  | sed 's/AVE[[:space:]]/AVE,/g' | sed 's/ER[[:space:]]/ER,/g' | awk '{ print $1,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' >> ../execNormal80.csv
#+end_src

- Dessa maneira funcionou

O script vai funcionar da seguinte forma primeiramente vou filtrar
pela palavra thread, a fim de conhecer o identificador respectivo de
cada thread, da seguinte maneira:

#+begin_src sh :results output :exports both
cd exec_normal_par80/
/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | awk '{ print $1,$2,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' | grep -i thread

#+end_src

#+RESULTS:
#+begin_example
THREAD_FORK 0 148300136098648 Model: "OpenMP" Requested       
THREAD_TEAM_BEGIN 8589934592 148300136631927 Thread Team:        
THREAD_TEAM_BEGIN 12884901888 148300136632116 Thread Team:        
THREAD_TEAM_BEGIN 4294967296 148300136632125 Thread Team:        
THREAD_TEAM_BEGIN 0 148300136632758 Thread Team:        
THREAD_TEAM_END 4294967296 148300137791884 Thread Team:        
THREAD_TEAM_END 0 148300137794262 Thread Team:        
THREAD_TEAM_END 8589934592 148300137794587 Thread Team:        
THREAD_TEAM_END 12884901888 148300137827954 Thread Team:        
THREAD_JOIN 0 148300137838547 Model: "OpenMP"        
#+end_example

A partir dessa saída é possível visualizar o momento em que o fork
inicia e termina. Além disso é possível visualizar o identificador de
cada thread.

#+begin_src sh :results output :exports both :tangle benchmarks/MM/scriptAnalyseTest.sh
cd exec_normal_par80/
array=$(/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | awk '{ print $1,$2,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' | grep -i THREAD_TEAM_BEGIN | awk ' { print $2 } ')

threads=4

x=1

while [ $x -le $threads ];
do
      echo $array | cut -d ' ' -f$x
	x=$((x+1))
done

#+end_src

#+RESULTS:
: 8589934592
: 12884901888
: 4294967296
: 0

Agora vou utilizar um desses identificadores de thread para recuperar
as medidas obtidas pelos =contadores de hardware= para as regiões de
código daquela thread.

#+begin_src sh :results output :exports both
cd benchmarks/MM/exec_normal_par80/
/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | sed 's/(//g' | sed 's/)//g' | sed 's/\"P/P/g' | sed 's/\"/,/g' | sed 's/C[[:space:]]/C,/g' | sed 's/[[:space:]]M/,M/g' | sed 's/[[:space:]]R/,R/g'  | sed 's/AVE[[:space:]]/AVE,/g' | sed 's/ER[[:space:]]/ER,/g' | awk '{ print $1,$2,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' | grep -i 8589934592
#+end_src

#+RESULTS:
#+begin_example
THREAD_TEAM_BEGIN 8589934592 148300136631927 Thread Team:        
METRIC, 8589934592 148300137337967 ,Metric: 0, PAPI_L1_DCM, 135, PAPI_L1_TCM, 550, PAPI_L2_ICM, 278, PAPI_L2_TCM, 367,
ENTER, 8589934592 148300137337967 ,Region: ,!$omp <3>       
METRIC, 8589934592 148300137347440 ,Metric: 0, PAPI_L1_DCM, 188, PAPI_L1_TCM, 831, PAPI_L2_ICM, 344, PAPI_L2_TCM, 458,
ENTER, 8589934592 148300137347440 ,Region: ,!$omp <4>       
METRIC, 8589934592 148300137764567 ,Metric: 0, PAPI_L1_DCM, 16509, PAPI_L1_TCM, 17407, PAPI_L2_ICM, 402, PAPI_L2_TCM, 1044,
ENTER, 8589934592 148300137764567 ,Region: ,!$omp @normal.c:51,       
METRIC, 8589934592 148300137775434 ,Metric: 0, PAPI_L1_DCM, 16596, PAPI_L1_TCM, 17558, PAPI_L2_ICM, 418, PAPI_L2_TCM, 1090,
LEAVE, 8589934592 148300137775434 ,Region: ,!$omp @normal.c:51,       
METRIC, 8589934592 148300137781926 ,Metric: 0, PAPI_L1_DCM, 16615, PAPI_L1_TCM, 17612, PAPI_L2_ICM, 430, PAPI_L2_TCM, 1104,
LEAVE, 8589934592 148300137781926 ,Region: ,!$omp <4>       
METRIC, 8589934592 148300137788125 ,Metric: 0, PAPI_L1_DCM, 16636, PAPI_L1_TCM, 17644, PAPI_L2_ICM, 430, PAPI_L2_TCM, 1105,
LEAVE, 8589934592 148300137788125 ,Region: ,!$omp <3>       
THREAD_TEAM_END 8589934592 148300137794587 Thread Team:        
#+end_example

- O script final para gerar os arquivos =csv= para análise será criado a
  partir dos fragmentos de script anteriores

#+begin_src sh :results output :exports both :tangle benchmarks/MM/scriptCSVExporter.sh

scorepFolders=$( ls | grep -i "exec_")

threads=4

for i in ${scorepFolders[@]};
do
      cd $i
      
      array=$(/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | awk '{ print $1,$2,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' | grep -i THREAD_TEAM_BEGIN | awk ' { print $2 } ')

	x=1
	
	echo "Folder: $i"
	while [ $x -le $threads ];
	do
		echo "Thread visited: $x"
    		idTmp=$(echo $array | cut -d ' ' -f$x)
		/home/gbmoro/Programas/scorep-2.0.2/bin/otf2-print traces.otf2 | sed 's/(//g' | sed 's/)//g' | sed 's/\"P/P/g' | sed 's/\"/,/g' | sed 's/C[[:space:]]/C,/g' | sed 's/[[:space:]]M/,M/g' | sed 's/[[:space:]]R/,R/g'  | sed 's/AVE[[:space:]]/AVE,/g' | sed 's/ER[[:space:]]/ER,/g' | awk '{ print $1,$2,$3,$4,$5,$8,$11,$16,$19,$24,$27,$28,$31 }' | grep -i $idTmp >> thread_$idTmp.csv
		x=$((x+1))
	done
	cd ..
done

#+end_src

#+RESULTS:
| Folder: exec_continuos_par100  |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_par50   |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_par60   |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_par80   |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_parT100 |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_parT50  |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_parT60  |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_continuos_parT80  |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_par100     |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_par50      |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_par60      |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_par80      |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_parT100    |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_parT50     |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_parT60     |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
| Folder: exec_normal_parT80     |
| Thread visited: 1              |
| Thread visited: 2              |
| Thread visited: 3              |
| Thread visited: 4              |
|                                |

** Analizando resultados obtidos

- O caso escolhido para ser o primeiro a ser analisado e plotado em
  gráfico é o algoritmo normal de entrada igual a 80. Seus rastros
  estão disponíveis na pasta:

#+begin_src sh :results output :exports both :tangle benchmarks/MM/exec_normal_par80/scriptOfGraph.sh
#path: benchmarks/MM/exec_normal_par80/

threadsFiles=$(ls | grep -i thre)
count=0;

for x in ${threadsFiles[@]};
do
	array=$(cat $x | awk '{ print $6 $7"\n"$8 $9"\n"$10 $11"\n"$12 $13}' | sed 's/(//g' | sed 's/)//g' | sed 's/\"/,/g' | sed 's/,,/,/g')
	idThread=$(echo $x | sed 's/.csv//g'| sed 's/thread_//g')
	let count=$count+1
	for i in ${array[@]};
	do
    	if [[ $i =~ .*@.* || $i =~ .*\<.* || $i =~ .*Threads.* || $i =~ .*Request*. ]]; then
	   		continue	    
		else
		    	echo "$count,$i" >> threadAnalyse.csv
		fi
	done
done

echo "thread,hardwareCounter,value" >> threadAnalyseOutput.csv
cat threadAnalyse.csv | sed 's/,,/,/g' |  sed 's/,*$//' >> threadAnalyseOutput.csv
rm threadAnalyse.csv 

#+end_src

#+RESULTS:

- Vou gerar um gráfico para visualizarmos o comportamento das threads
  nessa aplicação, através dos 4 contadores analisados.

#+begin_src R :results output graphics :file "graph.pdf" :exports both :session *Mnormalpar80*  :tangle benchmarks/MM/exec_normal_par80/plotScript.r
library(dplyr);
df <- read.csv("threadAnalyseOutput.csv");
k <- df %>% select(thread,hardwareCounter,value) %>%
     group_by(thread,hardwareCounter) %>%
     as.data.frame();

library(ggplot2);
ggplot(k, aes(x=as.factor(thread), y=value, color=hardwareCounter)) +
  geom_line(aes(group=thread)) +
  theme_bw() + scale_y_log10() +
  facet_wrap(~hardwareCounter);
#+end_src

#+RESULTS:
[[file:graph.pdf]]

* [2016-07-18 Mon 23:57] Retorno sobre as entradas anteriores         :Lucas:

Não consegui gerar a data desta entrada no formato visto nas seções
anteriores. Usei o atalho C-u C-c ! de acordo com o texto:
- http://orgmode.org/manual/Creating-timestamps.html

Reviso aqui o gráfico gerado na seção (veja seção imediatamente anterior):
- [[*Analizando resultados obtidos][Analizando resultados obtidos]]

Vamos olhar os dados (note o caminho relativo a raiz do repositório):

#+begin_src R :results output :session :exports both
df <- read.csv("benchmarks/MM/exec_normal_par80/threadAnalyseOutput.csv");
head(df);
#+end_src

#+RESULTS:
:   thread hardwareCounter value
: 1      1     PAPI_L1_DCM  4103
: 2      1     PAPI_L1_TCM 11234
: 3      1     PAPI_L2_ICM  4492
: 4      1     PAPI_L2_TCM  7141
: 5      1     PAPI_L1_DCM  4412
: 6      1     PAPI_L1_TCM 12150

O tempo desapareceu das medidas (imagino que ele deveria ser
mantido). Para tentar entender melhor o que foi feito, vamos olhar
para apenas uma thread e uma única métrica.

#+begin_src R :results output :session :exports both
head(df[df$thread == 1 & df$hardwareCounter == "PAPI_L1_DCM",]);
#+end_src

#+RESULTS:
:    thread hardwareCounter value
: 1       1     PAPI_L1_DCM  4103
: 5       1     PAPI_L1_DCM  4412
: 9       1     PAPI_L1_DCM  4523
: 13      1     PAPI_L1_DCM  4560
: 17      1     PAPI_L1_DCM  4589
: 21      1     PAPI_L1_DCM  4610

Parece estar tudo bem, o valor vai sempre aumentando.

Olhando o script =scriptOfGraph.sh=, parece-me que estás tirando fora a
informação de tempo. Não entendi também de onde tiraste a
informação das threads, pois olhando o arquivo =execNormal80.csv= (que
parece ser a origem dos dados), não tem dados sobre threads nas linhas
com as métricas. Veja:

#+begin_src sh :results output :session :exports both
ls -hl benchmarks/MM/execNormal80.csv
head benchmarks/MM/execNormal80.csv | grep METRIC
#+end_src

#+RESULTS:
: -rw-r--r-- 1 schnorr schnorr 6.3M Jul 18 23:42 benchmarks/MM/execNormal80.csv
: METRIC, 148299959479341 ,Metric: 0, PAPI_L1_DCM, 4103, PAPI_L1_TCM, 11234, PAPI_L2_ICM, 4492, PAPI_L2_TCM, 7141,
: METRIC, 148299959647641 ,Metric: 0, PAPI_L1_DCM, 4412, PAPI_L1_TCM, 12150, PAPI_L2_ICM, 4795, PAPI_L2_TCM, 7592,
: METRIC, 148299959668347 ,Metric: 0, PAPI_L1_DCM, 4523, PAPI_L1_TCM, 12576, PAPI_L2_ICM, 4846, PAPI_L2_TCM, 7690,

Olhando para o gráfico (e o código que o gerou):
[[file:benchmarks/MM/exec_normal_par80/graph.pdf]]

Alguns equívocos sobre o gráfico:
- estás desenhando com linha, quando deverias usar =geom_point()=
- evitar _sempre_ escalas logaritmicas, prefira escalas lineares

Existem alguns equívocos sobre os dados também. Por exemplo, após
agrupar com =group_by= nenhuma transformação nos dados é feita. Além
disso, entendo que como os valores dos contadores apenas aumentam
(veja acima), o ideal seria subtrair o maior valor do contador pelo
menor valor do mesmo contador. Isso permitiria tu obteres o valor
correto global para cada thread. Vejamos:

#+begin_src R :results output :session :exports both
k <- df[df$thread == 1 & df$hardwareCounter == "PAPI_L1_DCM",];
nrow(k);
#+end_src

#+RESULTS:
: [1] 76884

Existem várias medidas, vamos ver a diferença:

#+begin_src R :results output :session :exports both
head(k);
tail(k);
#+end_src

#+RESULTS:
#+begin_example
   thread hardwareCounter value
1       1     PAPI_L1_DCM  4103
5       1     PAPI_L1_DCM  4412
9       1     PAPI_L1_DCM  4523
13      1     PAPI_L1_DCM  4560
17      1     PAPI_L1_DCM  4589
21      1     PAPI_L1_DCM  4610
       thread hardwareCounter  value
307513      1     PAPI_L1_DCM 339304
307517      1     PAPI_L1_DCM 339321
307521      1     PAPI_L1_DCM 339494
307525      1     PAPI_L1_DCM 339497
307529      1     PAPI_L1_DCM 339595
307533      1     PAPI_L1_DCM 339604
#+end_example

Como não temos a coluna do tempo (foi removida desse CSV pelo script
mencionado acima), vamos plotar este valor em função da ordem das
medições. Mas primeiro, adicionar uma nova coluna com um identificador
de cada medição:

#+begin_src R :results output :session :exports both
k$seq = seq(1,nrow(k));
head(k);
tail(k);
#+end_src

#+RESULTS:
#+begin_example
   thread hardwareCounter value seq
1       1     PAPI_L1_DCM  4103   1
5       1     PAPI_L1_DCM  4412   2
9       1     PAPI_L1_DCM  4523   3
13      1     PAPI_L1_DCM  4560   4
17      1     PAPI_L1_DCM  4589   5
21      1     PAPI_L1_DCM  4610   6
       thread hardwareCounter  value   seq
307513      1     PAPI_L1_DCM 339304 76879
307517      1     PAPI_L1_DCM 339321 76880
307521      1     PAPI_L1_DCM 339494 76881
307525      1     PAPI_L1_DCM 339497 76882
307529      1     PAPI_L1_DCM 339595 76883
307533      1     PAPI_L1_DCM 339604 76884
#+end_example

Ótimo, agora vamos ao gráfico:

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session
library(ggplot2);
ggplot(k, aes(x=seq, y=value)) + geom_point() + theme_bw();
#+end_src

#+RESULTS:
[[file:/tmp/babel-10319ASZ/figure10319Cnl.png]]

Veja já que grave, o contador bate no limite e volta para 0. Isso é um
problema pois não podemos simplesmente considerar a diferenças entre o
valor máximo e o mínimo para ter um sumário do valor para cada thread.

Qual seria a solução para isso?

Veja o momento onde isso acontece.

#+begin_src R :results output :session :exports both
head(k[k$seq > 38439,]);
#+end_src

#+RESULTS:
:        thread hardwareCounter  value   seq
: 153757      1     PAPI_L1_DCM 339497 38440
: 153761      1     PAPI_L1_DCM 339595 38441
: 153765      1     PAPI_L1_DCM 339604 38442
: 153769      1     PAPI_L1_DCM   4103 38443
: 153773      1     PAPI_L1_DCM   4412 38444
: 153777      1     PAPI_L1_DCM   4523 38445

Isso é relativamente simples de detectar no momento do
rastreamento. Não há nenhum evento do Score-P que informa que houve
uma quebra do contador (pelo seu tamanho limitado)?

Isso deve ser resolvido antes de qualquer coisa.

_Tarefas_:
- adicionar uma coluna de tempo ao CSV
- tentar detectar a quebra do contador no Score-p

A ferramenta ReDFST parece que rastrea alguns contadores (não tenho
total certeza), e me parece também que ela detectaria. Mas os valores
de contadores obtidos são sempre globais. O que queremos é a evolução
do valor dos contadores _ao longo do tempo_.
* [13:44:21; 04.08.2016] Reexecução do benchmark MM com PAPI via Scorep - Contadores principais :Gabriel:
- Os principais contadores para visualizarmos o comportamento da
  aplicação via PAPI são: =PAPI_L1_DCH=, =PAPI_L2_DCH=, =PAPI_L3_TCM=,
  =PAPI_L1_DCA=, =PAPI_L2_DCA=, =PAPI_L3_DCA= e =PAPI_FP_OPS=.

Primeiramente vamos visualizar quais contadores temos disponíveis na
  máquina =beagle1= (terceira coluna é a disponibilidade do contador) :

#+begin_src sh :results output :exports both
sudo papi_avail | grep -i DCH
#+end_src

#+RESULTS:
| PAPI_L3_DCH  0x8000001d  No    No   Level 3 data cache hits |
| PAPI_L1_DCH  0x8000003e  No    No   Level 1 data cache hits |
| PAPI_L2_DCH  0x8000003f  Yes   Yes  Level 2 data cache hits |

#+begin_src sh :results output :exports both
sudo papi_avail | grep -i TCM
#+end_src

#+RESULTS:
| PAPI_L1_TCM  0x80000006  Yes   Yes  Level 1 cache misses |
| PAPI_L2_TCM  0x80000007  Yes   No   Level 2 cache misses |
| PAPI_L3_TCM  0x80000008  Yes   No   Level 3 cache misses |

#+begin_src sh :results output :exports both
sudo papi_avail | grep -i DCA
#+end_src

#+RESULTS:
| PAPI_L1_DCA  0x80000040  No    No   Level 1 data cache accesses |
| PAPI_L2_DCA  0x80000041  Yes   No   Level 2 data cache accesses |
| PAPI_L3_DCA  0x80000042  Yes   Yes  Level 3 data cache accesses |

#+begin_src sh :results output :exports both
sudo papi_avail | grep -i OPS
#+end_src

#+RESULTS:
| PAPI_FP_OPS  0x80000066  Yes   Yes  Floating point operations                                                               |
| PAPI_SP_OPS  0x80000067  Yes   Yes  Floating point operations; optimized to count scaled single precision vector operations |
| PAPI_DP_OPS  0x80000068  Yes   Yes  Floating point operations; optimized to count scaled double precision vector operations |

- Todos os contadores que serão utilizados no experimento são
  disponíveis na =beagle1=.
  
** Experimento
*** Projeto do Experimento

- Definição do projeto do experimento a ser realizado:

#+begin_src R :results output :session *experiment* :exports both
require(DoE.base);
  expDesign_MM <- fac.design (
           nfactors=2,
           replications=20,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(6,2),
           factor.names=list(
               app=c("normal_par","continuos_par","tiling_par","normal_parT","continuos_parT","tiling_parT"),
			size=c(50,80)));

  export.design(expDesign_MM,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("timeOfExecution","thread_region","idThread","PAPI_L2_DCH",
"PAPI_L2_DCA","PAPI_L1_TCM","PAPI_L2_TCM",
"PAPI_L3_TCM","PAPI_FP_OPS"));

#+end_src

#+RESULTS:
:  creating full factorial with 12 runs ...

- O full factorial pode ser visualizado na imagem gerada pelo seguinte
  script:

#+begin_src R :results output graphics :file "imagens/fullFactorialExpMM.png") :exports both :width 600 :height 400 :session *R* 
library(SixSigma)
library(grid)

effect<-"Hit, Misses das Caches e Operações FP"
causes.gr<-c("Versão", "Tamanho", "Threads")
causes<-vector(mode="list", length=length(causes.gr))

causes[1]<-list(c("normal_par","normal_parT", "continuos_par", "continuos_parT", "tiling_par", "tiling_parT"))
causes[2]<-list(c(50,80))
causes[3]<-list(c(32))

ss.ceDiag(effect, causes.gr, causes, sub="Experiment")

#+end_src

#+RESULTS:
[[file:imagens/fullFactorialExpMM.png]]

*** Plataforma de Execução

- As principais características da =beagle1= são:

#+begin_src sh :results output :exports both
lscpu
#+end_src

#+RESULTS:
| Architecture:          x86_64                                      |    |
| CPU op-mode(s):        32-bit, 64-bit                             |    |
| Byte Order:            Little Endian                              |    |
| CPU(s):                32                                         |    |
| On-line CPU(s) list:   0-                                         | 31 |
| Thread(s) per core:    2                                          |    |
| Core(s) per socket:    8                                          |    |
| Socket(s):             2                                          |    |
| NUMA node(s):          2                                          |    |
| Vendor ID:             GenuineIntel                               |    |
| CPU family:            6                                          |    |
| Model:                 45                                         |    |
| Stepping:              7                                          |    |
| CPU MHz:               2000.141                                   |    |
| BogoMIPS:              4001.23                                    |    |
| Virtualization:        VT-x                                       |    |
| L1d cache:             32K                                        |    |
| L1i cache:             32K                                        |    |
| L2 cache:              256K                                       |    |
| L3 cache:              20480K                                     |    |
| NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30 |    |
| NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31 |    |

*** Script de simulação do experimento

#+begin_src sh :results output :exports :tangle dados/scriptOfSimulationExpMM.sh
#!bin/bash


function toClear() {
	sudo rm -rf tmp tmp2 tmp.csv tmp2.csv Results_expMM.csv
}

function toExport() {
	export SCOREP_ENABLE_TRACING=true
	export SCOREP_METRIC_RUSAGE=ru_utime,ru_stime
	export SCOREP_TOTAL_MEMORY=3G
}

function execute() {
	scorepPath=/home/aulapinroot/Programs/scorep-2.0.2/bin

	cat expDesign_MM.csv | head -1 >> Results_expMM.csv

	lines=$(cat expDesign_MM.csv)

	h=0
	for i in ${lines[@]}; do

		if [ $h -gt 1 ]; then
		    
			echo "definindo variáveis de ambiente"
			echo "exportando as variáveis utilizadas pelo scorep"

			toExport

			name=$(echo $i | cut -d ',' -f1)
			runNoInStdOrder=$(echo $i | cut -d ',' -f2)
			runNo=$(echo $i | cut -d ',' -f3)
			runRP=$(echo $i | cut -d ',' -f4)
			app=$(echo $i | cut -d ',' -f5 | sed 's/\"//g')
			size=$(echo $i | cut -d ',' -f6 | sed 's/\"//g')

			echo "Executando -- $app"

			export SCOREP_METRIC_PAPI=PAPI_L2_DCH,PAPI_L2_DCA,PAPI_L1_TCM
			export SCOREP_EXPERIMENT_DIRECTORY="tmp"

			timeOfExecution=$(sudo -E ./$app $size | sed 's/HPCELO://g')
			
			$scorepPath/otf2-print tmp/traces.otf2 | awk ' { print $1,$3,$11,$15,$19,$20} ' | sed 's/[\")(,]//g' | sed 's/\ /,/g' | sed 's/,,,,//g' | sed 's/,ru_utime//g' >> tmp.csv
			
			toExport

			export SCOREP_METRIC_PAPI=PAPI_L2_TCM,PAPI_L3_TCM,PAPI_FP_OPS
			export SCOREP_EXPERIMENT_DIRECTORY="tmp2"

			sudo -E ./$app $size
			
			$scorepPath/otf2-print tmp2/traces.otf2 | awk ' { print $1,$3,$11,$15,$19,$20} ' | sed 's/[\")(,]//g' | sed 's/\ /,/g' | sed 's/,,,,//g' | sed 's/,ru_utime//g' >> tmp2.csv 


			paste tmp.csv tmp2.csv > tmpR.csv
			
			sed -i 's/\t/,/g' tmpR.csv

			res=$(cat tmpR.csv)

			for count in ${res[@]}; do
				echo "$name,$runNoInStdOrder,$runNo,$runRP,$app,$size,$timeOfExecution,$count" >> Results_expMM.csv
			done;

			
			sudo rm -rf tmp tmp2 tmp.csv tmp2.csv tmpR.csv 
		fi

		let h=$h+1;
		echo "interation $h"
	done
}

toClear

execute
#+end_src

